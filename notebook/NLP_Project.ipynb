{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKwSQ3yjxA6I"
      },
      "source": [
        "# Name Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/EliaFeltrin/KIND_project\n",
        "\n",
        "# TO DO In the introduction we have to put the introduction, the initial \n",
        "# consideration and so on, Elia's code has to be put here"
      ],
      "metadata": {
        "id": "kiR2_ghKCpKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f43f1fc-cffc-4250-cb01-4889a2e56529"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KIND_project'...\n",
            "remote: Enumerating objects: 236, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 236 (delta 0), reused 2 (delta 0), pack-reused 232\u001b[K\n",
            "Receiving objects: 100% (236/236), 10.61 MiB | 23.94 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General\n",
        "! pip install pandas\n",
        "! pip install tqdm\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "lliCd_Qx_ZL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934ab2fe-fb57-4da9-c7b0-2718e0435857"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering\n",
        "! pip install umap-learn\n",
        "! pip install sklearn\n",
        "! pip install nltk\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "DMeTdvZQ_Vz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CRF\n",
        "!pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite\n",
        "!pip install eli5\n",
        "\n",
        "from sklearn_crfsuite import metrics as crf_met\n",
        "from sklearn_crfsuite import CRF\n",
        "import eli5"
      ],
      "metadata": {
        "id": "FV7H9nhPIEkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325653fb-13dc-4220-d385-b744410a530f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_crfsuite\n",
            "  Cloning https://github.com/MeMartijn/updated-sklearn-crfsuite.git to /tmp/pip-install-ernp43d_/sklearn-crfsuite_0cc4e09cd2674bfd88ea1316d08c367f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MeMartijn/updated-sklearn-crfsuite.git /tmp/pip-install-ernp43d_/sklearn-crfsuite_0cc4e09cd2674bfd88ea1316d08c367f\n",
            "  Resolved https://github.com/MeMartijn/updated-sklearn-crfsuite.git to commit 675038761b4405f04691a83339d04903790e2b95\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (0.8.10)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn_crfsuite)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn_crfsuite\n",
            "  Building wheel for sklearn_crfsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn_crfsuite: filename=sklearn_crfsuite-0.3.6-py2.py3-none-any.whl size=10870 sha256=6b9d0fcaadad5cbb03450b08acafd17d7d8c37aa740e01b2b3d83dc058c27b57\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-essrk8ca/wheels/0b/bc/07/bd75a6f5fa2bf2ea05a5aad8d9ac66d2b5aab93dfd4e1a89de\n",
            "Successfully built sklearn_crfsuite\n",
            "Installing collected packages: python-crfsuite, sklearn_crfsuite\n",
            "Successfully installed python-crfsuite-0.9.9 sklearn_crfsuite-0.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting eli5\n",
            "  Downloading eli5-0.13.0.tar.gz (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.2/216.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.10/dist-packages (from eli5) (23.1.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from eli5) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from eli5) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from eli5) (1.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from eli5) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from eli5) (1.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from eli5) (0.20.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from eli5) (0.8.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->eli5) (2.1.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5) (3.1.0)\n",
            "Building wheels for collected packages: eli5\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=107730 sha256=f2afe71f405ff2b778d8654129cf938015fe8be75442f5a50b28acb88dc5ac02\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/58/ef/2cf4c306898c2338d51540e0922c8e0d6028e07007085c0004\n",
            "Successfully built eli5\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uSdgHpkxIGR"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08G5PAYnAUOr"
      },
      "source": [
        "### Package Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLQhCXCbxy-f"
      },
      "outputs": [],
      "source": [
        "# Installing the library needed in the following part of the project\n",
        "\n",
        "# Installing the utlity packages\n",
        "#! pip install scipy\n",
        "#! pip install numpy\n",
        "! pip install pandas\n",
        "\n",
        "# Installing a package for having the progress bar\n",
        "!pip install tqdm\n",
        "\n",
        "# Installing a natural language processing package\n",
        "! pip install nltk\n",
        "\n",
        "# Installing the packages for creating amazing plots\n",
        "#! pip install matplotlib\n",
        "! pip install wordcloud\n",
        "! pip install plotly\n",
        "! pip install --upgrade nbformat\n",
        "\n",
        "# Installing a package for sequence labeling, used for POS tagging and NER\n",
        "! pip install -U spacy\n",
        "\n",
        "# Installing the packages for creating the word embeddings\n",
        "! pip install --upgrade gensim\n",
        "! pip install fasttext\n",
        "\n",
        "# Installing one of the main machine learning libraries\n",
        "! pip install sklearn\n",
        "\n",
        "# Installing the packages for doing dimensionality reduction\n",
        "! pip install umap-learn\n",
        "\n",
        "# Installing packages for indexing the dataset\n",
        "! pip install python-terrier\n",
        "\n",
        "# Installing packages implementing conditional random fields\n",
        "! pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite\n",
        "! pip install eli5\n",
        "\n",
        "# Installing packages for transformers\n",
        "! pip install transformers==4.28.0\n",
        "! pip install datasets\n",
        "! pip install evaluate\n",
        "! pip install seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models download"
      ],
      "metadata": {
        "id": "jfZAu7CMRzP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6PbNJyzNAUOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f463d28e-5dff-4e79-fb84-95859a6b67b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-24 19:44:55.495418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting it-core-news-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_lg-3.5.0/it_core_news_lg-3.5.0-py3-none-any.whl (567.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.9/567.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-lg==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->it-core-news-lg==3.5.0) (2.1.2)\n",
            "Installing collected packages: it-core-news-lg\n",
            "Successfully installed it-core-news-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_lg')\n"
          ]
        }
      ],
      "source": [
        "# Dowloading an italian model from spacy\n",
        "! spacy download it_core_news_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEjHNHVAUOs"
      },
      "source": [
        "### Package import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXMMltVMVFQO"
      },
      "outputs": [],
      "source": [
        "# Importing the main packages\n",
        "\n",
        "# Importing the utlity packages\n",
        "import string\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Importing a package for having the progress bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Importing a natural language processing library\n",
        "import nltk\n",
        "\n",
        "# Importing the packages for creating amazing plots\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import plotly.express as px\n",
        "\n",
        "# Importing the packages for creating the word embeddings\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "# Importing the packages for doing dimensionality reduction\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "\n",
        "# Importing a package for the tf-idf representation of the sentences\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Importing a package for clustering\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "\n",
        "# Importing the packages for POS tagging\n",
        "import spacy as spc\n",
        "import it_core_news_lg\n",
        "\n",
        "# Importing packages for indexing the dataset\n",
        "import pyterrier as pt\n",
        "if not pt.started():\n",
        "  pt.init()\n",
        "\n",
        "# Importing packages implementing conditional random fields\n",
        "from sklearn_crfsuite import metrics as crf_met\n",
        "from sklearn_crfsuite import CRF\n",
        "import eli5\n",
        "\n",
        "# Importing packages for Transformers\n",
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import load_metric\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import evaluate\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "0u32r8WVcKps"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XLYGT2fNAUOt"
      },
      "outputs": [],
      "source": [
        "# Defining the names of the datasets\n",
        "dataset_names_train_IO = ['degasperi_train.tsv', 'fiction_train.tsv', 'moro_train.tsv', 'wikinews_train.tsv']\n",
        "dataset_names_test_IO = ['degasperi_test.tsv', 'fiction_test.tsv', 'moro_test.tsv', 'wikinews_test.tsv']\n",
        "dataset_names_train_BIO = ['degasperi_train_BIO.tsv', 'fiction_train_BIO.tsv','moro_train_BIO.tsv', 'wikinews_train_BIO.tsv']\n",
        "dataset_names_test_BIO = ['degasperi_test_BIO.tsv', 'fiction_test_BIO.tsv','moro_test_BIO.tsv', 'wikinews_test_BIO.tsv']\n",
        "\n",
        "# Defining the path to datasets\n",
        "PATH_TO_DATASETS_IO = '/content/KIND_project/datasets/Inside_outside_NER_notation'\n",
        "PATH_TO_DATASETS_BIO = '/content/KIND_project/datasets/BIO_tag_NER_notation'\n",
        "\n",
        "# Importing all the datasets in a dictionary\n",
        "datasets_train_dict_IO = {name: pd.read_csv(PATH_TO_DATASETS_IO+'/'+name, sep='[\\t|\\n]', names=['Token', 'Entity'], engine='python') for name in dataset_names_train_IO}\n",
        "datasets_test_dict_IO = {name: pd.read_csv(PATH_TO_DATASETS_IO+'/'+name, sep='[\\t|\\n]', names=['Token', 'Entity'], engine='python') for name in dataset_names_test_IO}\n",
        "datasets_train_dict_BIO = {name: pd.read_csv(PATH_TO_DATASETS_BIO+'/'+name, sep='[\\t|\\n]', names=['Token', 'Entity'], engine='python') for name in dataset_names_train_BIO}\n",
        "datasets_test_dict_BIO = {name: pd.read_csv(PATH_TO_DATASETS_BIO+'/'+name, sep='[\\t|\\n]', names=['Token', 'Entity'], engine='python') for name in dataset_names_test_BIO}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for dealing with the datasets\n",
        "\n",
        "In this session we define some funtions useful for having the correct structure of the dataset in order to use in the various techniques we implement in the following part of the notebook.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AIj4qBulAUOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "def get_string_from_df(dataframe_df, puntuaction, column_names=['Token', 'Entity']):\n",
        "  '''\n",
        "  Transforms the tokenized dataset into a single string.\n",
        "  It is assumed that the dataframe has two columns: one column containing the \n",
        "  tokens, so the words of the various sentences, by default it is named 'Token',\n",
        "  and the second containing the labels associated with that tokens, by default \n",
        "  it is named 'Entity'.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  dataframe_df: DataFrame\n",
        "    dataframe containing the tokenized dataset.\n",
        "  puntuaction: list\n",
        "    list containing the puntuaction, it is used in order to manage in a better\n",
        "    way the spaces in case of an element of puntuaction.\n",
        "  column_names: list, optional\n",
        "    ordered names of the columns, the one with index zero is used for extracting\n",
        "    the text from the DataFrame.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  text: str\n",
        "    string concatenating all the tokens of the dataset.\n",
        "\n",
        "  '''\n",
        "\n",
        "  text_df = dataframe_df.loc[:,column_names[0]]\n",
        "  text = text_df[0]\n",
        "  for token in text_df[1:]:\n",
        "    text += (' ' + token) if token not in puntuaction else token\n",
        "  return text"
      ],
      "metadata": {
        "id": "dbJQ8lSLAUOu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "def get_sentences_list_from_df(dataset_df, key=None, column_names=['Token', 'Entity'],\n",
        "                               lower=False):\n",
        "  '''\n",
        "  Extracts and returns the sentences from the DataFrame given as input.\n",
        "  It is assumed that the dataframe has two columns: one column containing the \n",
        "  tokens, so the words of the various sentences, by default it is named 'Token',\n",
        "  and the second containing the labels associated with that tokens, by default \n",
        "  it is named 'Entity'.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  dataset_df: DataFrame\n",
        "    dataframe containing the tokenized dataset\n",
        "  key: str, optional\n",
        "    name of the dataset from which the dataframe comes from.\n",
        "  column_names: list, optional\n",
        "    ordered names of the columns, the one with index zero is used for extracting\n",
        "    the text from the DataFrame.\n",
        "  lower: bool, optional\n",
        "    if True, the all the words will be transformed into lowercase words, if\n",
        "    False, they will not.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  sentences_list: list\n",
        "    list of the sentences contained in the dataset.\n",
        "  labels_list: list\n",
        "    list of lists of labels associated to the words of the sentences contained \n",
        "    in the dataset.\n",
        "  keys_list: list\n",
        "    list containing an entry for each sentence with the name of the dataset it\n",
        "    comes from.\n",
        "\n",
        "  '''\n",
        "  \n",
        "  print('Converting the DataFrame of the dataset' + key if key != None else '' \\\n",
        "        + 'into a list of strings')\n",
        "  \n",
        "  punctuation = string.punctuation\n",
        "  sentences_list = [[]]\n",
        "  labels_list = [[]]\n",
        "  keys_list = None\n",
        "  count = 0\n",
        "\n",
        "  for element in tqdm(dataset_df.iterrows()):\n",
        "    if str(element[1]['Token']) == '.':\n",
        "      sentences_list.append([])\n",
        "      labels_list.append([])\n",
        "      count += 1\n",
        "    elif str(element[1]['Token']) not in punctuation:\n",
        "      sentences_list[count].append(element[1]['Token'].lower() if lower else element[1]['Token'])\n",
        "      labels_list[count].append(element[1]['Entity'])\n",
        "  if key != None:\n",
        "    keys_list = [key for sentence in range(len(sentences_list))]\n",
        "  return sentences_list, labels_list, keys_list\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def remove_short_sentences(sentences_list, labels_list, keys_list = None, min_length=3):\n",
        "  '''\n",
        "  Removes the sentences with a length lower than a certain threshold.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  sentences_list: list\n",
        "    list of the sentences to be analyzed.\n",
        "  labels_list: list\n",
        "    list of lists of labels associated to the sentences.\n",
        "  keys_list: list, optional\n",
        "    list containing the name of the dataset from which each sentence.\n",
        "  min_lenght: int, optional\n",
        "    minimum number of words a sentence has to have to be kept.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  new_sentences_list: list\n",
        "    list of the sentences contained in the dataset.\n",
        "  new_labels_list: list\n",
        "    list of lists of labels associated to the words of the sentences contained \n",
        "    in the dataset.\n",
        "  new_keys_list: list\n",
        "    list containing an entry for each sentence with the name of the dataset it\n",
        "    comes from.\n",
        "\n",
        "  '''\n",
        "\n",
        "  print('Removing short sentences from the dataset')\n",
        "    \n",
        "  new_sentences_list = list()\n",
        "  new_labels_list = list()\n",
        "  new_keys_list = list()\n",
        "  for idx in tqdm(range(len(sentences_list))):\n",
        "    if len(sentences_list[idx]) >= min_length:\n",
        "      new_sentences_list.append(sentences_list[idx])\n",
        "      new_labels_list.append(labels_list[idx])\n",
        "      if keys_list != None:\n",
        "        new_keys_list.append(keys_list[idx])\n",
        "  return new_sentences_list, new_labels_list, new_keys_list\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def get_all_sentences_from_datasets(datasets, lower=False):\n",
        "  '''\n",
        "  Extracts and returns the sentences from every DataFrame in the dictionary\n",
        "  given as input.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  datasets: dict\n",
        "    dictionary of DataFrames containing the tokenized datasets.\n",
        "  lower: bool, optional\n",
        "    if True, the all the words will be transformed into lowercase words, if\n",
        "    False, they will not.\n",
        "  \n",
        "  Returns\n",
        "  -------\n",
        "  overall_sentences: list\n",
        "    list of the sentences contained in the datasets given in input.\n",
        "  overall_labels: list\n",
        "    list of lists of labels associated to the words of the sentences contained \n",
        "    in the datasets.\n",
        "  overall_keys: list\n",
        "    list containing an entry for each sentence with the name of the dataset it\n",
        "    comes from.\n",
        "\n",
        "  '''\n",
        "\n",
        "  overall_sentences = list()\n",
        "  overall_labels = list()\n",
        "  overall_keys = list()\n",
        "  for key in datasets.keys():\n",
        "    sentences, labels, keys = get_sentences_list_from_df(datasets[key], key=key, lower=lower)\n",
        "    sentences, labels, keys = remove_short_sentences(sentences, labels, keys_list=keys)\n",
        "    overall_sentences += sentences\n",
        "    overall_labels += labels\n",
        "    overall_keys += keys\n",
        "  return overall_sentences, overall_labels, overall_keys"
      ],
      "metadata": {
        "id": "UAUrIMICAUOu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "# Defining some function useful for having the correct structure of the dataset\n",
        "# in order to define the tf-idf representation\n",
        "\n",
        "def concatenate_sentences_tokens(sentences):\n",
        "  '''\n",
        "  Recombines the tokenized senteces into complete strings concatenating the\n",
        "  tokens of each sentence.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  sentences: list\n",
        "    list of tokenized sentences.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  concatenated_sentences: list\n",
        "    list of sentences.\n",
        "\n",
        "  '''\n",
        "  \n",
        "  concatenated_sentences = list()\n",
        "  for sentence in sentences:\n",
        "    new_sentence = ''\n",
        "    for token in sentence:\n",
        "      new_sentence += (token + ' ')\n",
        "    concatenated_sentences.append(new_sentence)\n",
        "  return concatenated_sentences"
      ],
      "metadata": {
        "id": "CnEtUn5rAUOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for computing some metrics\n",
        "\n",
        "In this session we define some funtions useful for computing the main performance indeces usually avaluated for understanding the goodness of a classificator."
      ],
      "metadata": {
        "id": "qdsB2Wg9393M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(predictions, true_labels, metrics_df=None, class_label='NotLabeled'):\n",
        "  '''\n",
        "  Computes and print metrics TP, TN, FP, FN, AC, RC, PC, F1\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  predictions: ndarray\n",
        "    predictions of samples obtained with a model\n",
        "  true_labels: ndarray\n",
        "    true labels of the samples\n",
        "  metrics_df: DataFrame, optional\n",
        "    DataFrame to which the computed statistics have to be put\n",
        "  class_label: str, optional\n",
        "    label identifing the belonging of the statistcs to its class\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  metrics_df: DataFrame\n",
        "    DataFrame containing the statistics contained in the parameter metrics_df\n",
        "    plus the statistics computed on the new predictions\n",
        "\n",
        "  '''\n",
        "\n",
        "  TP = np.sum(np.logical_and(predictions == 1., true_labels == 1.)) # Attacks accurately flagged as attacks\n",
        "  TN = np.sum(np.logical_and(predictions == 0., true_labels == 0.)) # Normal traffic accurately flagged as normal\n",
        "  FP = np.sum(np.logical_and(predictions == 1., true_labels == 0.)) # Normal traffic incorrectly flagged as attacks\n",
        "  FN = np.sum(np.logical_and(predictions == 0., true_labels == 1.)) # Attacks incorrectly flagged as normal \n",
        "\n",
        "  AC = ((TN + TP) / len(predictions)) * 100 # Accuracy\n",
        "  RC = (TP / (FN + TP)) * 100 # Recall or sensitivity\n",
        "  PR = (TP / (FP + TP)) * 100 # Precision\n",
        "  F1 = 2 * PR * RC / (PR + RC) # F1-Score\n",
        "\n",
        "  if metrics_df is None:\n",
        "    columns = ['Set of features', 'TP', 'TN', 'FP', 'FN', 'accuracy', 'recall', 'precision', 'F1-score']\n",
        "    metrics_df = pd.DataFrame([[class_label, TP, TN, FP, FN, AC, RC, PR, F1]], columns=columns)\n",
        "  else:\n",
        "    columns = ['Set of features', 'TP', 'TN', 'FP', 'FN', 'accuracy', 'recall', 'precision', 'F1-score']\n",
        "    metrics_df = pd.concat([metrics_df,pd.DataFrame([[class_label, TP, TN, FP, FN, AC, RC, PR, F1]], columns=columns)])\n",
        "  \n",
        "  return metrics_df\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def performance_metrics(predicted_labels, real_labels):\n",
        "  '''\n",
        "  Computes performance metrics given the predictions and the true labels\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  predictions: ndarray\n",
        "    predictions of samples obtained with a model\n",
        "  true_labels: ndarray\n",
        "    true labels of the samples\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  metrics_df: DataFrame\n",
        "    DataFrame containing the statistics contained in the parameter metrics_df\n",
        "    plus the statistics computed on the new predictions\n",
        "\n",
        "  '''\n",
        "  \n",
        "  metrics_df = None\n",
        "  classes = set(element for sentence in real_labels for element in sentence)\n",
        "  for tag in classes:\n",
        "    new_predicted_labels = np.array([1 if element == tag else 0 for sentence in predicted_labels for element in sentence])\n",
        "    new_real_labels = np.array([1 if element == tag else 0 for sentence in real_labels for element in sentence])\n",
        "    metrics_df = metrics(new_predicted_labels, new_real_labels, metrics_df=metrics_df, class_label=tag)\n",
        "  \n",
        "  return metrics_df"
      ],
      "metadata": {
        "id": "-OysvY3j4FkV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PMsuTVlfsNw"
      },
      "source": [
        "## Word embeddings representation\n",
        "\n",
        "A word embedding is the vectorial representation of a word that contains its sintactic and semantic information. It is used for achieving a numerical and dense representation of the words in an high dimensional space. Other types of representation of the words, such as the bag-of-words one, are sparse compared to word embeddings.\n",
        "The word embeddings allow to achieve better results in many fields of natural language processing.\n",
        "\n",
        "In this section, we train a Word2Vec model in order to obtain the word embeddings of the words contained in the dataset and we also load a model from FastText and find the representation of the dataset in terms of its vectors.\n",
        "\n",
        "The basic version of the word embeddings model is a artificial neural network composed by two layers.\n",
        "\n",
        "The inputs of the neural network are the words of the sentence to convert in the word embeddings representation.\n",
        "The first layer of the neural network is a fully connected linear layer with a number of neurons equals to the dimension of the embeddings.\n",
        "This layer is used to feed the last layer of the neural network that has the same number of outputs as inputs. On the output layer is applied a softmax function.\n",
        "The neural network is then trained in order to make it predict, for each word in input, the next word in a sentence.\n",
        "This is done, in the basic implementation by setting the input corresponding to the considered word to 1 and the other inputs to 0 and expecting as result the probability 1 on the expected word (the output of the softmax layer can be interpreted as a probability).\n",
        "The training can be performed using the cross entropy as loss function. At the end of the training the weights connecting each input to the first hidden layer are the values of the dimensions of the word embedding corresponding to the input word.\n",
        "\n",
        "Two of the most used architecture of the Word2Vec embedding model are CBOW and Skip-Gram.\n",
        "\n",
        "The Continuous Bag of Words (CBOW) method uses many words surrounding the considered word for predicting it. In the training step, the model sets to 1 the inputs corresponding to the words in the context of a word, the neural network has to predict the word inside the context. In this way the embedding is used to embed the context of a word for representing it.\n",
        "The Skip-gram uses a word to predict the words in the surroundings. In the training step, the input of the considered word will be set to 1 and the outputs the neural network has to learn are the probabilities of the words in its context, so the probabilities of the words in the surroundings.\n",
        "\n",
        "There are then optimizations of the training such as the negative sampling method or the computation of only some selected and meaningful outputs for each word in the train set.\n",
        "\n",
        "In some way the distribution in the various dimension is based on the similarity of the words in terms of semantics and usage. With word embeddings we can embed the context of the word inside its representation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word embeddings trained on all the data\n",
        "\n",
        "The choosen pipeline for the creation of the embeddings starts from the dataframe containing the tokens of the datasets.\n",
        "\n",
        "The preprocessing applied to the datasets in order to define the input of the Word2vec model is the following:\n",
        "- tokenization of the dataset (previously done by the providers of the datasets);\n",
        "- transformation of the input DataFrame into a list of lists of tokens, this is done merging the elements of the datasets into sentences. Since the datasets did not contain specific separator for the sentences, it is assumed that a sentence ends when in the DataFrane there is a dot. Therefor, the split in sentences of the tokens is done basing on the single dots.\n",
        "- lowercasing all the tokens\n",
        "\n",
        "We choose to try the definition of the word embeddings model on different portions of the dataset in order to compare the results. We expect that the more data are considered in the model definition, the more good will be the model in terms of information catched inside it.\n",
        "\n",
        "Firstly we try to define the word embeddings on the entire data we have since, as it is already been said, the larger is the dataset the better will be the our model and the wider will be the dictionary."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ijraczejAUOv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UOkb_6GAUOv"
      },
      "outputs": [],
      "source": [
        "# Merging the dictionaries of the trainsets and testsets\n",
        "datasets_for_embeddings = datasets_train_dict_IO.copy()\n",
        "datasets_for_embeddings.update(datasets_test_dict_IO)\n",
        "# Merging the lists of the names of the trainsets and testsets\n",
        "dataset_names_for_embeddings = dataset_names_train_IO + dataset_names_test_IO\n",
        "\n",
        "# Getting the sentences, the labels and the origin dataset of the sentences in\n",
        "# the correct format in order to create the embeddings representation of the words\n",
        "sentences, labels, sentences_keys = get_all_sentences_from_datasets(datasets_for_embeddings)\n",
        "\n",
        "# Printing 10 lists of token\n",
        "print('Here some examples of the shape of the sentences:')\n",
        "for i in range(10):\n",
        "  print(str(sentences[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ks3ebJKAUOv"
      },
      "outputs": [],
      "source": [
        "# To check that there are no tabs or new lines inside the tokens\n",
        "found = False\n",
        "for name in dataset_names_for_embeddings:\n",
        "  for i, el in datasets_for_embeddings[name].iterrows():\n",
        "    if '\\t' in el['Token'] or '\\n' in el['Token']:\n",
        "      found = True\n",
        "      print(el['Token'])\n",
        "if found:\n",
        "  print('There is something wrong, there tab or new line characters, are check the import of the dataset :(')\n",
        "else:\n",
        "  print('No tab or new line characters found, Great job!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwWF6C3sAUOv"
      },
      "outputs": [],
      "source": [
        "# Printing some information about the list of lists of token\n",
        "print('The total number of sentences in the dataset is ' + str(len(sentences)))\n",
        "length_list= []\n",
        "for idx,i in enumerate(sentences):\n",
        "  length_list.append(len(i))\n",
        "print('The maximum lenght of a sentence is ' + str(max(length_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hli5YYiaAUOv"
      },
      "outputs": [],
      "source": [
        "# Definition of the Word2Vec model\n",
        "embeddings_model = Word2Vec(sentences, vector_size=30, min_count=2, window=20)\n",
        "# Printing the length of the vocabulary\n",
        "print('The length of the vocabulary is' + str(len(embeddings_model.wv)) + ' words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT1DIssKAUOv"
      },
      "outputs": [],
      "source": [
        "# Searching the most similar word to a specific word\n",
        "term = 'governo'\n",
        "embeddings_model.wv.most_similar(term.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can try to find the most similar words to the given one. Using different values we can understand that the model is quite good and retrives words very related to the selected one."
      ],
      "metadata": {
        "id": "F3RkL3FhOHU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiLRR5MzAUOw"
      },
      "outputs": [],
      "source": [
        "# Choosing a subset of embedding vectors\n",
        "word_samples = random.sample(list(embeddings_model.wv.key_to_index), 500)\n",
        "word_vectors = embeddings_model.wv[word_samples]\n",
        "\n",
        "# Computing the dimensionality reduction of the word embeddings space\n",
        "tsne = TSNE(n_components=3, n_iter=2000)\n",
        "tsne_embeddings = tsne.fit_transform(word_vectors)\n",
        "x, y, z = np.transpose(tsne_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHcBd5-zAUOw"
      },
      "outputs": [],
      "source": [
        "# Plotting the word embeddings of the model\n",
        "fig = px.scatter_3d(x=x, y=y, z=z, text=word_samples)\n",
        "fig.update_traces(marker=dict(size=3, line=dict(width=2)), textfont_size=6)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8At4tFwAUOw"
      },
      "source": [
        "The second analysis is done on the word embeddings trained only on the training datasets that could be useful in the next part of the project since they can be used for performing named entity recognition. \n",
        "\n",
        "This is indeed a more realistic scenario, since train set and test set must be kept separate as much as possible in order to have an unbiased assessment of the models when evaluating it on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wArKi3xiAUOw"
      },
      "outputs": [],
      "source": [
        "# Getting the sentences, the labels and the origin dataset of the sentences in\n",
        "# the correct format in order to create the embeddings representation of the words\n",
        "sentences_train, labels_train, sentences_keys_train = get_all_sentences_from_datasets(datasets_train_dict_IO)\n",
        "\n",
        "# Definition of the Word2Vec model\n",
        "embeddings_model_train = Word2Vec(sentences_train, vector_size=30, min_count=2, window=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9PDHWg7AUOw"
      },
      "outputs": [],
      "source": [
        "# Printing the length of the vocabulary\n",
        "print('The length of the vocabulary is ' + str(len(embeddings_model.wv)) + ' words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaUHxOhOAUOw"
      },
      "outputs": [],
      "source": [
        "# Searching the most similar word to a specific word\n",
        "term = 'governo'\n",
        "embeddings_model_train.wv.most_similar(term.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWYjNVIYAUOw"
      },
      "outputs": [],
      "source": [
        "# Choosing a subset of embedding vectors\n",
        "word_samples_train = random.sample(list(embeddings_model_train.wv.key_to_index), 500)\n",
        "word_vectors_train = embeddings_model_train.wv[word_samples_train]\n",
        "\n",
        "# Computing the dimensionality reduction of the word embeddings space\n",
        "tsne = TSNE(n_components=3, n_iter=2000)\n",
        "tsne_embeddings = tsne.fit_transform(word_vectors_train)\n",
        "x_train, y_train, z_train = np.transpose(tsne_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcQAoHSnAUOx"
      },
      "outputs": [],
      "source": [
        "# Plotting the word embeddings of the model\n",
        "fig = px.scatter_3d(x=x_train, y=y_train, z=z_train, text=word_samples_train)\n",
        "fig.update_traces(marker=dict(size=3, line=dict(width=2)), textfont_size=6)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcJ9uK3yAUOx"
      },
      "source": [
        "The dictionary is a bit smaller but still big and the results are quite similar to the previous ones, in terms of understanding and search of the similar words and also the embedding space has a similar shape. \n",
        "\n",
        "Since train set and test set are usually separate and so I could create the embeddings model for the train set first and then model inside it the test set.\n",
        "\n",
        "However it has to be noted that the vocabulary is a bit smaller with respect to the one of the model trained over all the data. This is believable since the test set can have token that the train set doesn't present. This aspect could be a problem when the models fed by the embeddings have to be applied on the representation of the test set. Some words will not be converted in embeddings and the that words will could not be used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last embedding models trained are the ones computed on the train datasets separately."
      ],
      "metadata": {
        "id": "ZJYKN3AkQCG2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q7Qqy1wAUOx"
      },
      "outputs": [],
      "source": [
        "# Separating the train sets and collecting their sentences, labels and origin\n",
        "# dataset into a dictionary\n",
        "sentences_train_separate = {}\n",
        "labels_train_separate = {}\n",
        "embeddings_model_train_separate = {}\n",
        "keys_train_separate = {}\n",
        "for name in dataset_names_train_IO:\n",
        "  # Getting the sentences, the labels and the origin dataset of the sentences in\n",
        "  # the correct format in order to create the embeddings representation of the words\n",
        "  sentences_train_sep, labels_train_sep, keys_train_sep = get_all_sentences_from_datasets({name:datasets_train_dict_IO[name]})\n",
        "  sentences_train_separate[name] = sentences_train_sep\n",
        "  labels_train_separate[name] = labels_train_sep\n",
        "  keys_train_separate[name]  = keys_train_sep \n",
        "\n",
        "  # Definition of the Word2Vec models\n",
        "  embeddings_model_train_separate[name] = Word2Vec(sentences_train_sep, vector_size=30, min_count=2, window=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyBDbF5LAUOx"
      },
      "outputs": [],
      "source": [
        "# Printing the length of the vocabularies of the various datasets\n",
        "for name in dataset_names_train_IO:\n",
        "    print('The dictionary of the dataset ' + name + ' is long ' + str(len(embeddings_model_train_separate[name].wv)) + ' words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "monjRwjuAUOx"
      },
      "outputs": [],
      "source": [
        "# Searching the most similar word to a specific word\n",
        "for name in dataset_names_train_IO:\n",
        "    term = 'governo'\n",
        "    print(name + ':' + str(embeddings_model_train_separate[name].wv.most_similar(term.lower())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R9W3_o-AUOx"
      },
      "source": [
        "It is easy to understand that the dictionaries in this case are smaller since the overall words are splitted and analysed in many models.\n",
        "\n",
        "Trying to search the most similar embeddings to a given word in many different fields and for the different datasets, it can be seen that better performace are achieved by the datasets that are specialized in that field, e.g. fiction_train finds worst results (less related word embeddings) for the word 'governo' than the other datasets, which deal with news and politics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKHUhOncAUOx"
      },
      "outputs": [],
      "source": [
        "points_train_separate = {}\n",
        "word_samples_train_separate = {}\n",
        "for key in embeddings_model_train_separate:\n",
        "  # Choosing a subset of embedding vectors\n",
        "  word_samples_train_separate[key] = random.sample(list(embeddings_model_train_separate[key].wv.key_to_index), 500)\n",
        "  word_vector_train_separate = embeddings_model_train_separate.wv[word_samples_train_separate]\n",
        "\n",
        "  # Computing the dimensionality reduction of the word embeddings space\n",
        "  tsne = TSNE(n_components=3, n_iter=1000)\n",
        "  tsne_embeddings = tsne.fit_transform(word_vector_train_separate)\n",
        "  points_train_separate[key] = np.transpose(tsne_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpI-ond6AUOx"
      },
      "outputs": [],
      "source": [
        "# Plotting the word embeddings of the model\n",
        "for key in points_train_separate:\n",
        "  fig = px.scatter_3d(x=points_train_separate[key][0], y=points_train_separate[key][1],\n",
        "                      z=points_train_separate[key][2], text=word_samples_train_separate[key])\n",
        "  fig.update_traces(marker=dict(size=3, line=dict(width=2)), textfont_size=6)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6FpGcvnAUOy"
      },
      "source": [
        "### Computing the embeddings using a pretrained model FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPReFIjnAUOy"
      },
      "outputs": [],
      "source": [
        "# Downloading the pretrained model from the fasttext library\n",
        "!wget http://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.it.300.bin.gz\n",
        "!gzip -d cc.it.300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyIeWHLxAUOy"
      },
      "outputs": [],
      "source": [
        "# Instantiating the model\n",
        "ft_embedding_model = fasttext.load_model('cc.it.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_C3wIdLAUOy"
      },
      "outputs": [],
      "source": [
        "# Printing some statistics about the model\n",
        "print('The size of the vocabulary is ' + str(len(ft_embedding_model.get_words())))\n",
        "print('The length of the embeddings is '+ str(ft_embedding_model.get_dimension()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Searching the most similar word to a specific word\n",
        "term = 'legge'\n",
        "ft_embedding_model.get_nearest_neighbors(term.lower())"
      ],
      "metadata": {
        "id": "v46gvlZGrrPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fasttext_vector(word, model=None):\n",
        "  '''\n",
        "  Returns the fastText vector representation of a word.\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  word: str\n",
        "    word to convert into its vectorial representation.\n",
        "  model: fasttext.FastText._FastText\n",
        "    fastText model for creating the embedding. Providing it the computation of \n",
        "    the embedding is faster.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  word_vector: ndarray\n",
        "    fastText vector representation of a word.\n",
        "\n",
        "  '''\n",
        "  \n",
        "  if model == None:\n",
        "    model = fasttext.load_model('cc.it.300.bin')\n",
        "  word_vector = model.get_word_vector(ft_embedding_model.get_nearest_neighbors(word.lower())[0][1])\n",
        "  return word_vector"
      ],
      "metadata": {
        "id": "7vwzunT8sE0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the embedding representation of a word, assuming to represent a word\n",
        "# with its similar word in the model\n",
        "term = 'legge'\n",
        "get_fasttext_vector(term, ft_embedding_model)"
      ],
      "metadata": {
        "id": "4sbY2_S1tirf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the embedding representation of the dataset\n",
        "ft_embedding_train = [[get_fasttext_vector(sentences_train[i][j], ft_embedding_model) for j in range(len(sentences_train[i]))] for i in range(len(sentences_train))]"
      ],
      "metadata": {
        "id": "kDVUY6y6o88J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the dimensionality reduction of the word embeddings space\n",
        "sentence_samples_ft_train = random.sample(ft_embedding_train, 200)\n",
        "word_samples_ft_train = random.sample(sentence_samples_ft_train, 2)\n",
        "tsne = TSNE(n_components=3, n_iter=2000)\n",
        "tsne_embeddings = tsne.fit_transform(word_samples_ft_train)\n",
        "x_ft_train, y_ft_train, z_ft_train = np.transpose(tsne_embeddings)"
      ],
      "metadata": {
        "id": "KyhHyIFIrkna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the word embeddings of the model\n",
        "fig = px.scatter_3d(x=x_ft_train, y=y_ft_train, z=z_ft_train, text=word_samples_ft_train)\n",
        "fig.update_traces(marker=dict(size=3, line=dict(width=2)), textfont_size=6)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "85g52dSqwVeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgn1LECxAUOy"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "The clustering is an unsupervided machine learning technique useful for inspecting non-labeled data in order to find inside them hidden patterns or other information.\n",
        "In our case clustering is not needed for performing named entity recognition but it could useful for gain some additional knowledge about the dataset before proceeding in the sequence labeling task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the KIND dataset it is not possible to identify the different documents because no document separators are present in the data. Since it is not possible to identify the various documents, we decide to apply the clustering techniqes on the sentences. As we did in the embeddings section, we assume that the sentences were separate by the dot and we extract in this way them from the input files.\n",
        "\n",
        "In this section we try to investigate whether the four dataset are distinguishable basing on the representation of their sentences and so in some way they have different characteristics."
      ],
      "metadata": {
        "collapsed": false,
        "id": "BbrC9zJ_AUOy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUMklbsdAUOy"
      },
      "outputs": [],
      "source": [
        "# Importing the italian stopwords (taken from https://github.com/stopwords-iso/stopwords-it.git)\n",
        "with open('stopwords-it.txt', 'r') as f:\n",
        "    italian_stopwords = f.read()\n",
        "italian_stopwords_github = italian_stopwords.split('\\n')\n",
        "print('Number of stopwords in the repository https://github.com/stopwords-iso/stopwords-it.git: ' + str(len(italian_stopwords_github)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoyJuKM9AUOz"
      },
      "outputs": [],
      "source": [
        "# Downloading and importing the italian stopwords in the package nltk\n",
        "nltk.download('stopwords')\n",
        "italian_stopwords_nltk = nltk.corpus.stopwords.words('italian')\n",
        "print('Number of stopwords in the nltk library: ' + str(len(italian_stopwords_nltk)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Checking that all the stopwords of nltk are in the other dataset, better result with more stopwords\n",
        "count = 0\n",
        "for i in italian_stopwords_nltk:\n",
        "    if i in italian_stopwords_github:\n",
        "        count += 1\n",
        "print(str(count) + ' stopwords of the nltk library are in the Github repository')\n",
        "italian_stopwords = italian_stopwords_github"
      ],
      "metadata": {
        "id": "HlcGWK72AUOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Defining the vectorizer model\n",
        "vectorizer = TfidfVectorizer(max_df=0.5, min_df=3, stop_words=italian_stopwords_github, use_idf=True)\n",
        "# Fitting the vectorizer model\n",
        "vectorizer.fit(concatenate_sentences_tokens(sentences))\n",
        "\n",
        "# Given that we are evaluating sentences the frequncy can be lower for saying that we have a stopword"
      ],
      "metadata": {
        "id": "bWG5z2noAUOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Extracting the vocabulary\n",
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "\n",
        "print('The vocabulary is long ' + str(len(vocabulary)) + ' words')"
      ],
      "metadata": {
        "id": "2Bh3XX3aAUOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# The words look reasonable and the vocabulary seems to not have many stopwords inside\n",
        "sorted(random.sample(vocabulary.tolist(),100))"
      ],
      "metadata": {
        "id": "jdsVliRNAUOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Converting the strings into vectors\n",
        "sentences_vector = vectorizer.transform(concatenate_sentences_tokens(sentences))"
      ],
      "metadata": {
        "id": "52kRljRQAUOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "sentences_vector[0].multiply(sentences_vector[0]).sum()"
      ],
      "metadata": {
        "id": "023nFyxlAUOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "max_score = 0\n",
        "sentence_idx = 21\n",
        "for i in range(sentences_vector.shape[0]):\n",
        "    if i != sentence_idx:\n",
        "        score = sentences_vector[sentence_idx].multiply(sentences_vector[i]).sum()\n",
        "        if score > max_score:\n",
        "            max_score = score\n",
        "            max_score_idx = i\n",
        "print('Sentence index ' + str(sentence_idx) + ': ' + str(sentences[sentence_idx]))\n",
        "print('Most similar sentence is the one with index ' + str(max_score_idx) + ': ' + str(sentences[max_score_idx]))\n",
        "print('The score is ' + str(max_score))"
      ],
      "metadata": {
        "id": "0_NeyGPrAUOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to find the most similar sentences to a given sentence, it is possible to see that the metrics of similarity are quite low, very often in the interval (0.20, 0.40). Moreover the retrieved sentences have some sort of similarities, they have some words in common, but they are not very similar in the semantics or in the field of application of the sentence."
      ],
      "metadata": {
        "collapsed": false,
        "id": "JykECfayAUO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------ DA QUI SISTEMA\n",
        "\n",
        "Here we try to cluster the sentences in the 4 datsets, so we expect four clasters, we use the K-means clustering method."
      ],
      "metadata": {
        "collapsed": false,
        "id": "CNXFHEy7AUO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Defining the labels of the clustering\n",
        "keys_datasets = list()\n",
        "for key in sentences_keys:\n",
        "    keys_datasets.append(key.replace('_train.tsv', '').replace('_test.tsv', ''))\n",
        "# Applying the K-means clustering\n",
        "num_clusters= len(set(keys_datasets))\n",
        "kmeans_model = KMeans(n_clusters=num_clusters, max_iter=1000, n_init=2, verbose=True, random_state=2307)\n",
        "kmeans_model.fit(sentences_vector)"
      ],
      "metadata": {
        "id": "Hnzfig-tAUO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "for i in range(num_clusters):\n",
        "    centroid = kmeans_model.cluster_centers_[i]\n",
        "    sorted_terms = centroid.argsort()[::-1]\n",
        "    print('Centroid of cluster ' + str(i))\n",
        "    print([vocabulary[j] for j in sorted_terms[:20]])"
      ],
      "metadata": {
        "id": "uRfuh3a3AUO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF9qbE8MAUO0"
      },
      "outputs": [],
      "source": [
        "print(\"Top terms per cluster:\")\n",
        "vocabulary = vectorizer.get_feature_names_out()\n",
        "\n",
        "for i in range(kmeans_model.n_clusters):\n",
        "    centroid = kmeans_model.cluster_centers_[i]\n",
        "    sorted_terms = centroid.argsort()[::-1]\n",
        "    print(f\"Cluster {i}:\\t{[vocabulary[j] for j in sorted_terms[:10]]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "print('Number of sentences in: ')\n",
        "\n",
        "for i in range(kmeans_model.n_clusters):\n",
        "    print(f\"Cluster {i}: {np.sum(kmeans_model.labels_ == i)}\")"
      ],
      "metadata": {
        "id": "UFnTQM3vAUO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(\"Intrinsic evaluation measures:\")\n",
        "print(\"Within-cluster sum-of-squares:\", str(kmeans_model.inertia_))\n",
        "print(\"Silhouette coefficient:\", str(metrics.silhouette_score(sentences_vector, kmeans_model.labels_)))"
      ],
      "metadata": {
        "id": "CcGDnhv4AUO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using TF-IDF vectors it is not possible to distinguish the datasets, the clusters found are not the ones of the "
      ],
      "metadata": {
        "collapsed": false,
        "id": "NJAOdYITAUO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "print('Extrinsic evaluation measures:')\n",
        "print(\"Homogeneity:\", str(metrics.homogeneity_score(keys_datasets, kmeans_model.labels_)))\n",
        "print(\"Completeness:\", str(metrics.completeness_score(keys_datasets, kmeans_model.labels_)))\n",
        "print(\"V-measure:\", str(metrics.v_measure_score(keys_datasets, kmeans_model.labels_)))\n",
        "print(\"Adjusted Rand-Index:\", str(metrics.adjusted_rand_score(keys_datasets, kmeans_model.labels_)))"
      ],
      "metadata": {
        "id": "DvvsSvHxAUO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd = TruncatedSVD(3) # We keep the most informative directions (for being able to draw the points - this is not so informative)\n",
        "reduced_data = svd.fit_transform(sentences_vector)\n",
        "\n",
        "[x,y,z] = np.transpose(reduced_data)\n",
        "[x,y,z]"
      ],
      "metadata": {
        "id": "tyLwFwl7Zbky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(x, y, z, c=LabelEncoder().fit_transform(keys_datasets), marker='.')"
      ],
      "metadata": {
        "id": "aKY7BCmGZbpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(x, y, z, c=kmeans_model.labels_, marker='.')"
      ],
      "metadata": {
        "id": "7nrdrQPfZbsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dato il primo sketch del clustering, probabilmente non clusterizzo nemmeno un po' per dataset."
      ],
      "metadata": {
        "id": "qjDzNDKbZbwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following we try to apply the clustering to the embeddings representation af the dataset in order to see whether the results are better in this case or not."
      ],
      "metadata": {
        "id": "sFmVvg6gDgoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_model = KMeans(n_clusters=num_clusters, max_iter=1000, n_init=2, verbose=True, random_state=2307)\n",
        "kmeans_model.fit(sentences_vector)"
      ],
      "metadata": {
        "id": "bot5arzdPwjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zciY89OhPwl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6ZV9RrTPwof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Do clusteting with embeddings"
      ],
      "metadata": {
        "id": "02-GHS6nAUO1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfbNEkJZgDJe"
      },
      "source": [
        "## POS tagging\n",
        "\n",
        "**Part-of-speech** tagging is the process of marking up a word in a text with the corresponding part of speech, based on both its definition and its context.\n",
        "The POS Tagging here plays a crucial role to understand in what context the word is used in the sentence.\n",
        "\n",
        "We will perform POS tagging using the **spaCy** libary.\n",
        "After the tokenization, spaCy can parse and tag a given Doc. This is made thanks to a trained pipeline and its statistical models, which enable spaCy to make predictions of which tag o label most likely applies in this context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creation of the POS tags files\n",
        "\n",
        "In the following part of code we created some files containing the POS tags for each dataset and also che combination of them. This to improve the performances for the next steps and to avoid every time to do everything from the start."
      ],
      "metadata": {
        "id": "6Ls1yQMgQ_GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_pos_tags_on_file(filename, dataset):\n",
        "\n",
        "  '''\n",
        "  Takes as input a dataset and writes into a file the pos tags for each sentence\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename: Str\n",
        "    File name that has to be used to save the pos tags\n",
        "\n",
        "  dataset: DataFrame\n",
        "    Dataset that contains the tokens of the text.\n",
        "\n",
        "  '''\n",
        "\n",
        "  sentences, labels, _ = get_sentences_list_from_df(dataset, lower=False)\n",
        "  pos_tags = get_pos_tags(sentences)\n",
        "  with open(f'{filename}.txt', 'w+') as f:\n",
        "    for line in pos_tags:\n",
        "      f.write(' '.join(line)+'\\n')\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "qp81_qUJRElm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For every dataset it writes the respective file with the pos tags\n",
        "for dataset_name, dataset in datasets_train_dict_BIO.items():\n",
        "  write_pos_tags_on_file(f'POS_tags_{dataset_name[:-4]}', dataset)"
      ],
      "metadata": {
        "id": "rxs2WcCHRIM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the pos tags for the train and test datasets merged\n",
        "df_merged_train = pd.concat(datasets_train_dict_BIO.values(), ignore_index=True)\n",
        "df_merged_test = pd.concat(datasets_test_dict_BIO.values(), ignore_index=True)\n",
        "\n",
        "write_pos_tags_on_file('trainsets', df_merged_train)\n",
        "write_pos_tags_on_file('testsets', df_merged_test)"
      ],
      "metadata": {
        "id": "Wm7NrWvbROGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot stats POS tags\n"
      ],
      "metadata": {
        "id": "ObHE-HlrRST4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the model here for being sure the model is available\n",
        "import it_core_news_lg\n",
        "\n",
        "def get_pos_tags(sentences):\n",
        "  \n",
        "  '''\n",
        "  Computes and returns the pos tags of the sentences of the dataset.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  sentences: list\n",
        "    list of lists of words that is the list of the tokenized sentences.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pos_tags: list\n",
        "    list of lists of part-of-speech tags, in the same format of the input \n",
        "    sentences, there is a mapping one-to-one between words and tags.\n",
        "\n",
        "  '''\n",
        "\n",
        "  # Loading the model for POS tagging\n",
        "  model = it_core_news_lg.load()\n",
        "  \n",
        "  # Join the tokens into sentences\n",
        "  sentences_tokens_merged = [' '.join(sentence) for sentence in sentences]\n",
        "\n",
        "  pos_tags = []\n",
        "  for sentence in sentences_tokens_merged: \n",
        "    # Process the sentence with SpaCy\n",
        "    doc = model(sentence)\n",
        "    sentence_pos = []\n",
        "    for token in doc:\n",
        "      sentence_pos.append(token.pos_)\n",
        "    pos_tags.append(sentence_pos)\n",
        "\n",
        "  return pos_tags"
      ],
      "metadata": {
        "id": "RJeZrL-NJdYq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos_tags_file(train_or_test=True):\n",
        "  '''\n",
        "  Retrieves the part-of-speech tags of the dataset in a format easy to use in\n",
        "  our analysis.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  train_or_test: bool, optional\n",
        "    if True, the method returns the tags of the train set, if False, the method \n",
        "    returns the tags of the test set.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pos_tags: list\n",
        "    part-of-speech tags of the requested dataset.\n",
        "\n",
        "  '''\n",
        "\n",
        "  with open('/content/KIND_project/pos_tags/POS_tags_'+('train' if train_or_test else 'test')+'sets.txt', 'r') as f:\n",
        "    pos_tags = [line.replace('\\n', '').split(' ') for line in f]\n",
        "    return pos_tags\n",
        "  f.close()\n",
        "\n",
        "def get_pos_tags_specific_file(dataset_name):\n",
        "\n",
        "'''\n",
        "Retrieves the part-of-speech tags of a specific dataset in a format easy to use in our analysis.\n",
        "\n",
        "Parameters\n",
        "----------\n",
        "file_name: Str\n",
        "  Name of the dataset\n",
        "\n",
        "Returns\n",
        "-------\n",
        "pos_tags: list\n",
        "  part-of-speech tags of the requested dataset.\n",
        "\n",
        "'''\n",
        "\n",
        "with open(f'/content/KIND_project/pos_tags/POS_tags_{dataset_name}.txt', 'r') as f:\n",
        "  pos_tags = [line.replace('\\n', '').split(' ') for line in f]\n",
        "  return pos_tags\n",
        "f.close()"
      ],
      "metadata": {
        "id": "m86rJDWSJhBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPRbor2ATNqR"
      },
      "outputs": [],
      "source": [
        "def merge_counters(counter1, counter2):\n",
        "\n",
        "  '''\n",
        "  Takes 2 counters with different shapes and in the smallest one ad also the key that are currently inside with a value of 0\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  counter1: Counter\n",
        "    Counter with smallest shape that has to be incremented\n",
        "  counter2: Counter\n",
        "    Counter with the larger shape\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  new_counter: Counter\n",
        "    Counter containing all the tuple of the smallest one and the tuples (key, 0) of the larger one that were no present in the small one\n",
        "  '''\n",
        "  new_counter = counter1    \n",
        "\n",
        "  for key, value in counter2.items():\n",
        "    if key not in new_counter.keys():\n",
        "      new_counter[key] = 0 \n",
        "\n",
        "  return new_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzmUyHYDw-eR"
      },
      "outputs": [],
      "source": [
        "def plot_wordCloud_counters(counters):\n",
        "\n",
        "  '''\n",
        "  Takes as input a list of counters and it plots the wordCloud\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  cunters: list(Counter)\n",
        "    List of counters that has to be plotted. It does not require that all the counters has the same shape\n",
        "\n",
        "  '''\n",
        "\n",
        "  word_cloud_counter = Counter()\n",
        "  for counter in list_counters:\n",
        "    word_cloud_counter.update(counter)\n",
        "  # Generate a word cloud from the POS counts\n",
        "  wordcloud = WordCloud(background_color='white').generate_from_frequencies(word_cloud_counter)\n",
        "\n",
        "  # Plot the word cloud\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oFiL_p2unFX"
      },
      "outputs": [],
      "source": [
        "def plot_groupedBar_counters(counters):\n",
        "\n",
        "  '''\n",
        "  Takes as input a list of counters and it plots in the same bar chart the counts\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  cunters: list(Counter)\n",
        "    List of counters that has to be plotted. It does not require that all the counters has the same shape\n",
        "\n",
        "  '''\n",
        "  \n",
        "  max_length = max(map(len, list_counters))                         # max length of the counters\n",
        "  max_position = list(map(len, list_counters)).index(max_length)    # position in the list of the counter with max length\n",
        "\n",
        "  # For each counter that is not the one of maximum dimension I merge it with all the other ones. The result is a list with counters having all the same keys\n",
        "  for i in range(len(list_counters)):\n",
        "    if i != max_position:\n",
        "      list_counters[i] = merge_counters(list_counters[i], list_counters[max_position])\n",
        "\n",
        "  # We plot each counter inside the bar chart\n",
        "  x = np.arange(max_length)\n",
        "  width=0.2\n",
        "  multiplier = 0\n",
        "  for counter in list_counters:\n",
        "    offset = width * multiplier\n",
        "    labels, values = zip(*sorted(counter.items()))\n",
        "    plt.bar(x + offset, values, width=width)\n",
        "    multiplier += 1\n",
        "\n",
        "  plt.title(\"POS Tag Frequency Distribution Degasperi\")\n",
        "  plt.xlabel(\"POS Tag\")\n",
        "  plt.ylabel(\"Frequency\")\n",
        "  plt.xticks(x + width, sorted(list_counters[max_position]), rotation='vertical')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code, we load all the tags for considering all the datasets of train as a unique one and we count the number of occurrence for each of them.\n",
        "After that, we plot their occurrences."
      ],
      "metadata": {
        "id": "3RxvxxorJs-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each tag and plot them\n",
        "pos_freq_all_datasets = Counter([tag for sentence in get_pos_tags_file() for tag in sentence])\n",
        "list_counters = [pos_freq_all_datasets]\n",
        "plot_groupedBar_counters(list_counters)"
      ],
      "metadata": {
        "id": "ef15ar7pJ2Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we do the same as before, but for any training dataset to visualize the \n",
        "differences between the datasets."
      ],
      "metadata": {
        "id": "LsDpin4LJ7CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_counters = []\n",
        "# For each train dataset we take the save the occurrences of the tags\n",
        "for dataset_name in datasets_train_dict_BIO.keys():\n",
        "  tags = get_pos_tags_specific_file(dataset_name[:-4])\n",
        "  pos_freq = Counter([tag for sentence in tags for tag in sentence])\n",
        "  list_counters.append(pos_freq)\n",
        "\n",
        "# Plot of all the counter in the same plot to compare them\n",
        "plot_groupedBar_counters(list_counters)\n",
        "plot_wordCloud_counters(list_counters)"
      ],
      "metadata": {
        "id": "eQ5Kn_4HJ9PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnJ0Rfx5AUO2"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "Indexing is the process by which search engines organize information before a search to enable super-fast responses to queries. \n",
        "Searching through individual pages for keywords and topics would be a very slow process for search engines to identify relevant information. Instead, search engines use an inverted index, also known as a reverse index.\n",
        "An inverted index is a system wherein a database of text elements is compiled along with pointers to the documents which contain those elements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, since we don't have a dataset of documents we decided to index the sentences inside our datasets.\n",
        "To do that we have to create the sentences from the dictionary of datasets."
      ],
      "metadata": {
        "id": "dYtA4wp9LXrN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjbbdpR0AUO2"
      },
      "outputs": [],
      "source": [
        "sentences, labels, keys = get_all_sentences_from_datasets(datasets_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we create the dataset of sentences adding also the Id to indetify them while the query part."
      ],
      "metadata": {
        "id": "FOedSyMGMnVQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIJ856g5AUO2"
      },
      "outputs": [],
      "source": [
        "sentences_df = pd.DataFrame(columns=['docno', 'text'])\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "    sentences_df.loc[i] = [f's{i}', ' '.join(sentences[i])]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, we index the sentences dataframe. The index, with all its data structures, is written into a directory that we will call `index`.\n",
        "`Index_Ref` provides the location where the index is stored."
      ],
      "metadata": {
        "id": "zimvJV0gM3Kj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeAsq2sHAUO5"
      },
      "outputs": [],
      "source": [
        "index_path = \"./index\"\n",
        "\n",
        "indexer = pt.DFIndexer(index_path, overwrite=True)\n",
        "index_ref = indexer.index(sentences_df['text'], sentences_df['docno'])\n",
        "index_ref.toString()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can now load the index and print it.\n",
        "This is a Terrier index structure, which provides methods such as:\n",
        " - `getCollectionStatistics()`\n",
        " - `getInvertedIndex()`\n",
        " - `getLexicon()`\n",
        "\n",
        " Let's see what is returned by the `CollectionStatistics()` method."
      ],
      "metadata": {
        "id": "BBT349HRNRmO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTfdsLQ8AUO5"
      },
      "outputs": [],
      "source": [
        "index = pt.IndexFactory.of(index_ref)\n",
        "print(index.getCollectionStatistics().toString())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have indexed our documents, we can run a search over the document collection.\n",
        "Here we used the TF-IDF weighting formula to rank the results. \n",
        "\n",
        "The `search()` method returns a dataframe with columns:\n",
        " - `qid`: the query identifier\n",
        " - `docid`: integer identifier for document \n",
        " - `docno`: string identifier for document\n",
        " - `rank`: rank position\n",
        " - `score`: tf-idf score\n",
        " - `query`: the input query"
      ],
      "metadata": {
        "id": "AkadPwj6O0Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "br = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
        "\n",
        "queries = pd.DataFrame([[\"query1\", \"festa\"], [\"query2\", \"ammiraglio\"], [\"query3\", \"messaggio audio\"]], columns=[\"qid\", \"query\"])\n",
        "br(queries)"
      ],
      "metadata": {
        "id": "sjvmRsOdG4QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conditional random fields\n",
        "\n",
        "Conditinal random fields can be seen as an extention of the Hidden Markov Models.\n",
        "\n",
        "HMM take a sequence of data, in our case a sequence of tokens (words), and assumes that the observations are given by a set of state that we don't observe but which we are interested to tag. There are transition probabilities between the states in the sequence (probability of going into a specific next state) and there are emission probability for each state that states which is the probability of a observation in a given state.\n",
        "\n",
        "HMM is a generative model: it aim to model the joint probability of hidden state and observation simultaniously. Framework in which we understand the way the data we have are generated.\n",
        "\n",
        "HMM has some limitation:\n",
        "- transition and emission probabilities are static, in every position of the sentence in our case (we expect that the probabilities can change in different positions of a sentence?);\n",
        "- each state depends only on the previous state but in natural language processing this is not the case, also the observations can depend on previous states in the speech (but we can imagine the dependency can be in the current state).\n",
        "\n",
        "CRF\n",
        "CRFs are a type of discriminative undirected probabilistic graphical model.\n",
        "We can imagine this model as an extension of the HMM where we can draw whatever dependency we want between the states. We have an undirected graph where the nodes are the states. The states are connected with each other in an arbitrary way and a states depends on the state to which it is connected through an edge.\n",
        "\n",
        "More general framework for catching the dependencies between the state and also between states and observations.\n",
        "\n",
        "We want to find the probability of the state conditioned the observations. We don't find the process generation. In our case we want to discriminate whether a token is part of an entity or not given the sentence.\n",
        "Often we use a variant of the method called linear chain CRF, in case we have a big dataset. In case of LCCRF we consider associations between states that are next to each other (consequent) in time and we consider relations with observations and all the hidden states.\n",
        "\n",
        "The underlying idea is the one of the logistic regression.\n",
        "\n",
        "--- continue ---"
      ],
      "metadata": {
        "id": "Xbca80El2prc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function definition\n",
        "\n",
        "Here we define some function needed for performing the named entity recognition task using crf-suite."
      ],
      "metadata": {
        "id": "_iW_yMemOo1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_features_from_word(sentence, position, prefix=''):\n",
        "  '''\n",
        "  Converts a word of the sentence into its representation given by a standard\n",
        "  set of features that we consider the basis from which the feature vector can\n",
        "  be enlarged\n",
        "\n",
        "  This method has been implemented for having a crfsuite format representation\n",
        "  of the dataset in order to apply use the conditional random fields framework\n",
        "  provided by the sklearn_crfsuite package.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  sentence: list\n",
        "    list of the words composing the sentence.\n",
        "  position: integer\n",
        "    position in the list of the word that has to be converted into its feature \n",
        "    vector representation.\n",
        "  prefix: str, optional\n",
        "    string that can be appended before the names of the attributes of the \n",
        "    dictionary of features for specifying additional information.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  standard_word_features: dict\n",
        "    dictionary of the standard features of the word\n",
        "\n",
        "  '''\n",
        "\n",
        "  standard_word_features = None\n",
        "  if position < len(sentence) and position >= 0:\n",
        "    word = sentence[position]\n",
        "    standard_word_features = {\n",
        "          prefix+'word' : word,\n",
        "          prefix+'word_lowercase' : word.lower(),\n",
        "          prefix+'first_letter_upper' : word[0].isupper(),\n",
        "          prefix+'all_letters_upper' : word.isupper(),\n",
        "          prefix+'all_digits' : word.isdigit(),\n",
        "          prefix+'position' : position,\n",
        "    }\n",
        "  return standard_word_features\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def get_gazetteer_features(sentence, position, gazetteer_dict, prefix='', \n",
        "                           gazetteer_entity_lenght=3):\n",
        "  '''\n",
        "  Returns the features related to the belonging of a word of the sentence to the \n",
        "  list of known entities.\n",
        "\n",
        "  This method has been implemented for having a crfsuite format representation\n",
        "  of the dataset in order to apply use the conditional random fields framework\n",
        "  provided by the sklearn_crfsuite package.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  sentence: list\n",
        "    list of the words composing the sentence.\n",
        "  position: integer\n",
        "    position in the list of the word that has to be converted into its feature \n",
        "    vector representation.\n",
        "  gazetteer_dict: dict\n",
        "    dictionary containing a elements the sets of the known entities, each set \n",
        "    contains a different type of entity.\n",
        "  prefix: str, optional\n",
        "    string that can be appended before the names of the attributes of the \n",
        "    dictionary of features for specifying additional information.\n",
        "  gazetteer_entity_lenght: integer\n",
        "    maximum length, in terms of number of words, of the known named entities.\n",
        "    Incresing the length of the names of the entities will end up in a bigger \n",
        "    computational complexity but could end up in better results.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  gazetteer_features: dict\n",
        "    dictionary of the features of the word reguarding the belonging of the word\n",
        "    to the know entity lists.\n",
        "    \n",
        "  '''\n",
        "\n",
        "  gazetteer_features = {}\n",
        "  for key in gazetteer_dict:\n",
        "    found = False\n",
        "    for ent_len in range(1, gazetteer_entity_lenght+1):\n",
        "      for i in range(ent_len):\n",
        "        if position - i >= 0 and position + ent_len - i - 1 < len(sentence):\n",
        "          entity = ' '.join(sentence[(position - i):(position + ent_len - i - 1 + 1)])\n",
        "          if i == 0:\n",
        "            if entity in gazetteer_dict[key]:\n",
        "              gazetteer_features.update({'B-'+key: True})\n",
        "              found = True\n",
        "              #break\n",
        "          else:\n",
        "            if entity in gazetteer_dict[key]:\n",
        "              gazetteer_features.update({'I-'+key: True})\n",
        "              found = True\n",
        "              #break\n",
        "      #if found:\n",
        "        #break\n",
        "    if not found:\n",
        "      gazetteer_features.update({key: False})\n",
        "\n",
        "  return gazetteer_features\n",
        "    \n",
        "################################################################################\n",
        "\n",
        "def transform_word_to_features(sentence, position, postags=None, embeddings=None,\n",
        "                               previous_words_to_embed=1, next_words_to_embed=1,\n",
        "                               gazetteer=None, gazetteer_entity_lenght=3):\n",
        "  '''\n",
        "  Converts a word of the sentence into its representation given by a set of\n",
        "  features. Some features are inserted by default some others can be requested\n",
        "  through setting the optional parameters.\n",
        "\n",
        "  This method has been implemented for having a crfsuite format representation\n",
        "  of the dataset in order to apply use the conditional random fields framework\n",
        "  provided by the sklearn_crfsuite package.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  sentence: list\n",
        "    list of the words composing the sentence.\n",
        "  position: integer\n",
        "    position in the list of the word that has to be converted into its feature \n",
        "    vector representation.\n",
        "  postags: list\n",
        "    list of the part-of-speech tags related to the words of the sentence. This\n",
        "    list has to be of the same length of the sentence list.\n",
        "  embeddings: list\n",
        "    list of the embeddings related to the words of the sentence. This list has \n",
        "    to be of the same length of the sentence list.\n",
        "  previous_words_to_embed: integer\n",
        "    number of words preceeding the considered word that hava to be embedded in \n",
        "    the feature representation of the considered word.\n",
        "  next_words_to_embed: integer\n",
        "    number of words following the considered word that hava to be embedded in \n",
        "    the feature representation of the considered word.\n",
        "  gazetteer: dict\n",
        "    dictionaty containing the known named entities. If None, it is assumed that\n",
        "    gazetteer cannot be used.\n",
        "  gazetteer_entity_lenght: integer\n",
        "    maximum length, in terms of number of words, of the known named entities.\n",
        "    Incresing the length of the names of the entities will end up in a bigger \n",
        "    computational complexity but could end up in better results.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  word_features: dict\n",
        "    dictionary of the features of the word\n",
        "\n",
        "  '''\n",
        "  word_features = None\n",
        "  if position < len(sentence) and position >= 0:\n",
        "    # Getting the standard features for the word to convert into features\n",
        "    word_features = standard_features_from_word(sentence, position)\n",
        "\n",
        "    # Adding the embedding representation of the word to the features\n",
        "    if embeddings != None:\n",
        "      word_features.update({'embedding' : embeddings[:,position]})\n",
        "    # Adding the POS tag to the features of the word\n",
        "    if postags != None:\n",
        "      word_features.update({'postag': postags[position]})\n",
        "    \n",
        "    # Embedding the context of the sentence inside the feature representation of\n",
        "    # the word, adding the features of the previous words in the sentence\n",
        "    if previous_words_to_embed > 0:\n",
        "      i = 1\n",
        "      while i < previous_words_to_embed + 1 and position-i >= 0:\n",
        "        word_features.update(standard_features_from_word(sentence, position-i, prefix='-'+str(i)+':'))\n",
        "        if postags != None:\n",
        "          word_features.update({'-'+str(i)+':postag': postags[position-i]})\n",
        "        i += 1\n",
        "\n",
        "    # Embedding the context of the sentence inside the feature representation of\n",
        "    # the word, adding the features of the previous words in the sentence\n",
        "    if next_words_to_embed > 0:\n",
        "      i = 1\n",
        "      while i < next_words_to_embed + 1 and position+i <= len(sentence)-1:\n",
        "        word_features.update(standard_features_from_word(sentence, position+i, prefix='+'+str(i)+':'))\n",
        "        if postags != None:\n",
        "          word_features.update({'+'+str(i)+':postag': postags[position+i]})\n",
        "        i += 1\n",
        "\n",
        "    if gazetteer != None:\n",
        "      word_features.update(get_gazetteer_features(sentence, position, gazetteer))\n",
        "  else:\n",
        "    print('Wrong input, the index of the word in the sentence is not valid.')\n",
        "  return word_features \n",
        "\n",
        "################################################################################\n",
        "\n",
        "def transform_sentences_to_features(sentences, postags=None, embeddings=None, \n",
        "                                    previous_words_to_embed=1, next_words_to_embed=1,\n",
        "                                    gazetteer=None, gazetteer_entity_lenght=3):\n",
        "  '''\n",
        "  Converts the sentences into their representation given by a list of \n",
        "  dictionaries of features. Some features are inserted by default some others \n",
        "  can be requested through setting the optional parameters.\n",
        "\n",
        "  This method has been implemented for having a crfsuite format representation\n",
        "  of the dataset in order to apply use the conditional random fields framework\n",
        "  provided by the sklearn_crfsuite package.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  sentence: list\n",
        "    list of lists of the words composing the sentences.\n",
        "  postag: list\n",
        "    list of lists of the part-of-speech tags related to the words of the \n",
        "    sentences. This list of lists has to have the same dimensions of the \n",
        "    sentence list.\n",
        "  embeddings: list\n",
        "    list of lists of the embeddings related to the words of the sentences. This \n",
        "    list of lists has to have the same dimensions of the sentence list.\n",
        "  previous_words_to_embed: integer\n",
        "    number of words preceeding the considered word that have to be embedded in \n",
        "    the feature representation of the considered word.\n",
        "  next_words_to_embed: integer\n",
        "    number of words following the considered word that havae to be embedded in \n",
        "    the feature representation of the considered word.\n",
        "  gazetteer: dict\n",
        "    dictionaty containing the known named entities. If None, it is assumed that\n",
        "    gazetteer cannot be used.\n",
        "  gazetteer_entity_lenght: integer\n",
        "    maximum length, in terms of number of words, of the known named entities.\n",
        "    Incresing the length of the names of the entities will end up in a bigger \n",
        "    computational complexity but could end up in better results.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  sentence_features: list\n",
        "    representation of the sentences as a list of lists of dictionaries of features\n",
        "  \n",
        "  '''\n",
        "  \n",
        "  all_sentences_features = []\n",
        "  for index,sentence in tqdm(enumerate(sentences)):\n",
        "    sentence_features = []\n",
        "    for i in range(len(sentence)):\n",
        "      sentence_features.append(transform_word_to_features(sentence, i, postags=(postags[index] if postags != None else None), \n",
        "            embeddings=embeddings, previous_words_to_embed=previous_words_to_embed, \n",
        "            next_words_to_embed=next_words_to_embed, gazetteer=gazetteer,\n",
        "            gazetteer_entity_lenght=gazetteer_entity_lenght))\n",
        "    all_sentences_features.append(sentence_features)\n",
        "  return all_sentences_features\n"
      ],
      "metadata": {
        "id": "etWsTi-_pshB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Providing example of the format of input that takes the functions generating\n",
        "# the features from the datasets\n",
        "sentences_input_example = [\n",
        "    ['Mark', 'Carman', 'è', 'fantastico'],\n",
        "    ['Anche', 'il', 'dottor', 'Scotti', 'è', 'fantastico'], \n",
        "    ['Ciao', 'sono', 'Mike', 'e', 'sono', 'a', 'Milano']]\n",
        "\n",
        "# Providing example of the output given by the functions generating the features\n",
        "# from the datasets\n",
        "output_features_example = transform_sentences_to_features(sentences_input_example)\n",
        "output_features_example"
      ],
      "metadata": {
        "id": "bHbzjBH9TEja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb54d16-c478-47b0-ab21-deae53a447e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3it [00:00, 13301.18it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'word': 'Mark',\n",
              "   'word_lowercase': 'mark',\n",
              "   'first_letter_upper': True,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 0,\n",
              "   '+1:word': 'Carman',\n",
              "   '+1:word_lowercase': 'carman',\n",
              "   '+1:first_letter_upper': True,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 1},\n",
              "  {'word': 'Carman',\n",
              "   'word_lowercase': 'carman',\n",
              "   'first_letter_upper': True,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 1,\n",
              "   '-1:word': 'Mark',\n",
              "   '-1:word_lowercase': 'mark',\n",
              "   '-1:first_letter_upper': True,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 0,\n",
              "   '+1:word': 'è',\n",
              "   '+1:word_lowercase': 'è',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 2},\n",
              "  {'word': 'è',\n",
              "   'word_lowercase': 'è',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 2,\n",
              "   '-1:word': 'Carman',\n",
              "   '-1:word_lowercase': 'carman',\n",
              "   '-1:first_letter_upper': True,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 1,\n",
              "   '+1:word': 'fantastico',\n",
              "   '+1:word_lowercase': 'fantastico',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 3},\n",
              "  {'word': 'fantastico',\n",
              "   'word_lowercase': 'fantastico',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 3,\n",
              "   '-1:word': 'è',\n",
              "   '-1:word_lowercase': 'è',\n",
              "   '-1:first_letter_upper': False,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 2}],\n",
              " [{'word': 'Anche',\n",
              "   'word_lowercase': 'anche',\n",
              "   'first_letter_upper': True,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 0,\n",
              "   '+1:word': 'il',\n",
              "   '+1:word_lowercase': 'il',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 1},\n",
              "  {'word': 'il',\n",
              "   'word_lowercase': 'il',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 1,\n",
              "   '-1:word': 'Anche',\n",
              "   '-1:word_lowercase': 'anche',\n",
              "   '-1:first_letter_upper': True,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 0,\n",
              "   '+1:word': 'dottor',\n",
              "   '+1:word_lowercase': 'dottor',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 2},\n",
              "  {'word': 'dottor',\n",
              "   'word_lowercase': 'dottor',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 2,\n",
              "   '-1:word': 'il',\n",
              "   '-1:word_lowercase': 'il',\n",
              "   '-1:first_letter_upper': False,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 1,\n",
              "   '+1:word': 'Scotti',\n",
              "   '+1:word_lowercase': 'scotti',\n",
              "   '+1:first_letter_upper': True,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 3},\n",
              "  {'word': 'Scotti',\n",
              "   'word_lowercase': 'scotti',\n",
              "   'first_letter_upper': True,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 3,\n",
              "   '-1:word': 'dottor',\n",
              "   '-1:word_lowercase': 'dottor',\n",
              "   '-1:first_letter_upper': False,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 2,\n",
              "   '+1:word': 'è',\n",
              "   '+1:word_lowercase': 'è',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 4},\n",
              "  {'word': 'è',\n",
              "   'word_lowercase': 'è',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 4,\n",
              "   '-1:word': 'Scotti',\n",
              "   '-1:word_lowercase': 'scotti',\n",
              "   '-1:first_letter_upper': True,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 3,\n",
              "   '+1:word': 'fantastico',\n",
              "   '+1:word_lowercase': 'fantastico',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 5},\n",
              "  {'word': 'fantastico',\n",
              "   'word_lowercase': 'fantastico',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 5,\n",
              "   '-1:word': 'è',\n",
              "   '-1:word_lowercase': 'è',\n",
              "   '-1:first_letter_upper': False,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 4}],\n",
              " [{'word': 'Ciao',\n",
              "   'word_lowercase': 'ciao',\n",
              "   'first_letter_upper': True,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 0,\n",
              "   '+1:word': 'sono',\n",
              "   '+1:word_lowercase': 'sono',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 1},\n",
              "  {'word': 'sono',\n",
              "   'word_lowercase': 'sono',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 1,\n",
              "   '-1:word': 'Ciao',\n",
              "   '-1:word_lowercase': 'ciao',\n",
              "   '-1:first_letter_upper': True,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 0,\n",
              "   '+1:word': 'Mike',\n",
              "   '+1:word_lowercase': 'mike',\n",
              "   '+1:first_letter_upper': True,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 2},\n",
              "  {'word': 'Mike',\n",
              "   'word_lowercase': 'mike',\n",
              "   'first_letter_upper': True,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 2,\n",
              "   '-1:word': 'sono',\n",
              "   '-1:word_lowercase': 'sono',\n",
              "   '-1:first_letter_upper': False,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 1,\n",
              "   '+1:word': 'e',\n",
              "   '+1:word_lowercase': 'e',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 3},\n",
              "  {'word': 'e',\n",
              "   'word_lowercase': 'e',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 3,\n",
              "   '-1:word': 'Mike',\n",
              "   '-1:word_lowercase': 'mike',\n",
              "   '-1:first_letter_upper': True,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 2,\n",
              "   '+1:word': 'sono',\n",
              "   '+1:word_lowercase': 'sono',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 4},\n",
              "  {'word': 'sono',\n",
              "   'word_lowercase': 'sono',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 4,\n",
              "   '-1:word': 'e',\n",
              "   '-1:word_lowercase': 'e',\n",
              "   '-1:first_letter_upper': False,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 3,\n",
              "   '+1:word': 'a',\n",
              "   '+1:word_lowercase': 'a',\n",
              "   '+1:first_letter_upper': False,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 5},\n",
              "  {'word': 'a',\n",
              "   'word_lowercase': 'a',\n",
              "   'first_letter_upper': False,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 5,\n",
              "   '-1:word': 'sono',\n",
              "   '-1:word_lowercase': 'sono',\n",
              "   '-1:first_letter_upper': False,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 4,\n",
              "   '+1:word': 'Milano',\n",
              "   '+1:word_lowercase': 'milano',\n",
              "   '+1:first_letter_upper': True,\n",
              "   '+1:all_letters_upper': False,\n",
              "   '+1:all_digits': False,\n",
              "   '+1:position': 6},\n",
              "  {'word': 'Milano',\n",
              "   'word_lowercase': 'milano',\n",
              "   'first_letter_upper': True,\n",
              "   'all_letters_upper': False,\n",
              "   'all_digits': False,\n",
              "   'position': 6,\n",
              "   '-1:word': 'a',\n",
              "   '-1:word_lowercase': 'a',\n",
              "   '-1:first_letter_upper': False,\n",
              "   '-1:all_letters_upper': False,\n",
              "   '-1:all_digits': False,\n",
              "   '-1:position': 5}]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application of the CRF to the dataset"
      ],
      "metadata": {
        "id": "ubxUwELuuXda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the sentences and the labels from the training dataset\n",
        "sentences_merged_train_BIO, labels_merged_train_BIO, _ = get_all_sentences_from_datasets(datasets_train_dict_BIO, lower=False)\n",
        "# Getting the sentences and the labels from the test dataset\n",
        "sentences_merged_test_BIO, labels_merged_test_BIO, _ = get_all_sentences_from_datasets(datasets_test_dict_BIO, lower=False)"
      ],
      "metadata": {
        "id": "ezEL64YtO_6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of a gazetteer set\n",
        "PATH_TO_GAZETTEER = '/content/KIND_project/datasets/Entities'\n",
        "gazetteer_loc = set(line.replace('LOC','').strip() for line in open(PATH_TO_GAZETTEER + '/it-LOC-wikipedia.txt', encoding='utf-8'))\n",
        "gazetteer_org = set(line.replace('ORG','').strip() for line in open(PATH_TO_GAZETTEER + '/it-ORG-wikipedia.txt', encoding='utf-8'))\n",
        "gazetteer_per = set(line.replace('PER','').strip() for line in open(PATH_TO_GAZETTEER + '/it-PER-wikipedia.txt', encoding='utf-8'))\n",
        "gazetteer_dict = {\n",
        "    'LOC': gazetteer_loc,\n",
        "    'ORG': gazetteer_org,\n",
        "    'PER': gazetteer_per,\n",
        "}\n",
        "gazetteer = gazetteer_loc.union(gazetteer_org).union(gazetteer_per)"
      ],
      "metadata": {
        "id": "bpOtthwaTMTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting the model without POS tags"
      ],
      "metadata": {
        "id": "3ck75C9xO1cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the training dataset in the one required for training the model to\n",
        "# perform the named entity recognition task through the conditional random \n",
        "# fields method\n",
        "sentences_features_merged_train_BIO = transform_sentences_to_features(sentences_merged_train_BIO)\n",
        "\n",
        "# Converting the test dataset in the one required for performing the named \n",
        "# entity recognition task through the conditional random fields method\n",
        "sentences_features_merged_test_BIO = transform_sentences_to_features(sentences_merged_test_BIO)"
      ],
      "metadata": {
        "id": "LKI0m1gJqID_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the CRF model for NER\n",
        "ner_crf_model = CRF(algorithm='lbfgs',\n",
        "                    c1=0.2,\n",
        "                    c2=0.2,\n",
        "                    max_iterations=200,\n",
        "                    verbose=True,\n",
        "                    all_possible_transitions=False)\n",
        "\n",
        "# Fitting the CRF model using the training set\n",
        "ner_crf_model.fit(sentences_features_merged_train_BIO, labels_merged_train_BIO)"
      ],
      "metadata": {
        "id": "oIQ2LLKQh2k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the labels on which the performance evaluation has to be done\n",
        "classes_BIO = list(ner_crf_model.classes_)\n",
        "# Removing the class of words that are not entities in order to have the \n",
        "# evaluation of the performance considering only the classes of the entities\n",
        "classes_BIO.remove('O')"
      ],
      "metadata": {
        "id": "lf8_Mou9Py1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the lables on the train set\n",
        "prediction_merged_train_BIO = ner_crf_model.predict(sentences_features_merged_train_BIO)\n",
        "# Predicting the lables on the test set\n",
        "prediction_merged_test_BIO = ner_crf_model.predict(sentences_features_merged_test_BIO)\n",
        "\n",
        "# Computing the flat F1 score on the train set\n",
        "f1_score_train_BIO = crf_met.flat_f1_score(labels_merged_train_BIO, prediction_merged_train_BIO,\n",
        "                                       average='weighted', labels=classes_BIO)\n",
        "# Computing the flat F1 score on the test set\n",
        "f1_score_test_BIO = crf_met.flat_f1_score(labels_merged_test_BIO, prediction_merged_test_BIO,\n",
        "                                      average='weighted', labels=classes_BIO)\n",
        "\n",
        "print('Flat F1 score on the trainset: ' + str(f1_score_train_BIO))\n",
        "print('Flat F1 score on the testset: ' + str(f1_score_test_BIO))"
      ],
      "metadata": {
        "id": "HNkvBdDBMnyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Performance on the trainset')\n",
        "performance_merged_train_BIO = performance_metrics(prediction_merged_train_BIO, labels_merged_train_BIO)\n",
        "performance_merged_train_BIO"
      ],
      "metadata": {
        "id": "IKr7ddtbR1kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Performance on the testset')\n",
        "performance_merged_test_BIO = performance_metrics(prediction_merged_test_BIO, labels_merged_test_BIO)\n",
        "performance_merged_test_BIO"
      ],
      "metadata": {
        "id": "48mtNBTpRjOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for class_label in classes_BIO:\n",
        "  #print(class_label+': '+str(crf_met.flat_f1_score(labels_merged_train_BIO, prediction_merged_test_BIO,\n",
        "  #                                                 average='weighted', labels=class_label)))"
      ],
      "metadata": {
        "id": "HW3HUv30TnKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eli5.show_weights(ner_crf_model, top=30)"
      ],
      "metadata": {
        "id": "7lJ-Rw9-Bvy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting the model with also gazetteer"
      ],
      "metadata": {
        "id": "qZOf_7G_WKHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the training dataset in the one required for training the model to\n",
        "# perform the named entity recognition task through the conditional random \n",
        "# fields method, here it is considered also whether a word, or sequence of words,\n",
        "# is in the set of known entities.\n",
        "sentences_features_merged_train_BIO_gaz = transform_sentences_to_features(sentences_merged_train_BIO,\n",
        "                                                                          previous_words_to_embed=3, \n",
        "                                                                          next_words_to_embed=3,\n",
        "                                                                          gazetteer = gazetteer_dict,\n",
        "                                                                          gazetteer_entity_lenght= 6)\n",
        "\n",
        "# Converting the test dataset in the one required for test the model to perform\n",
        "# the named entity recognition task through the conditional random fields method,\n",
        "# here it is considered also whether a word, or sequence of words, is in the set\n",
        "# of known entities.\n",
        "sentences_features_merged_test_BIO_gaz = transform_sentences_to_features(sentences_merged_test_BIO,\n",
        "                                                                         previous_words_to_embed=3,\n",
        "                                                                         next_words_to_embed=3,\n",
        "                                                                         gazetteer = gazetteer_dict,\n",
        "                                                                         gazetteer_entity_lenght = 6)"
      ],
      "metadata": {
        "id": "wgkGo3-BfwJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the CRF model for NER\n",
        "ner_crf_model_gaz = CRF(algorithm='lbfgs',\n",
        "                        c1=0.1,\n",
        "                        c2=0.1,\n",
        "                        max_iterations=100,\n",
        "                        verbose=True,\n",
        "                        all_possible_transitions=False)\n",
        "\n",
        "# Fitting the CRF model using the training set\n",
        "ner_crf_model_gaz.fit(sentences_features_merged_train_BIO_gaz, labels_merged_train_BIO)"
      ],
      "metadata": {
        "id": "15uRy39Of6Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the labels on which the performance evaluation has to be done\n",
        "classes_BIO_gaz = list(ner_crf_model_gaz.classes_)\n",
        "# Removing the class of words that are not entities in order to have the \n",
        "# evaluation of the performance considering only the classes of the entities\n",
        "classes_BIO_gaz.remove('O')"
      ],
      "metadata": {
        "id": "bq-fbaVxf_Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the lables on the train set\n",
        "prediction_merged_train_BIO_gaz = ner_crf_model_gaz.predict(sentences_features_merged_train_BIO_gaz)\n",
        "# Predicting the lables on the test set\n",
        "prediction_merged_test_BIO_gaz = ner_crf_model_gaz.predict(sentences_features_merged_test_BIO_gaz)\n",
        "\n",
        "# Computing the flat F1 score on the train set\n",
        "f1_score_train_BIO_gaz = crf_met.flat_f1_score(labels_merged_train_BIO, prediction_merged_train_BIO_gaz,\n",
        "                                       average='weighted', labels=classes_BIO_gaz)\n",
        "# Computing the flat F1 score on the test set\n",
        "f1_score_test_BIO_gaz = crf_met.flat_f1_score(labels_merged_test_BIO, prediction_merged_test_BIO_gaz,\n",
        "                                      average='weighted', labels=classes_BIO_gaz)\n",
        "\n",
        "print('Flat F1 score on the trainset: ' + str(f1_score_train_BIO_gaz))\n",
        "print('Flat F1 score on the testset: ' + str(f1_score_test_BIO_gaz))"
      ],
      "metadata": {
        "id": "ASBuESzVf_YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Performance on the trainset')\n",
        "performance_merged_train_BIO_gaz = performance_metrics(prediction_merged_train_BIO_gaz, labels_merged_train_BIO)\n",
        "performance_merged_train_BIO_gaz"
      ],
      "metadata": {
        "id": "DOoBhx6j2Wk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Performance on the testset')\n",
        "performance_merged_test_BIO_gaz = performance_metrics(prediction_merged_test_BIO_gaz, labels_merged_test_BIO)\n",
        "performance_merged_test_BIO_gaz"
      ],
      "metadata": {
        "id": "9MgwV-8EWnpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for class_label in classes:\n",
        "  #print(class_label+': '+str(crf_met.flat_f1_score(labels_test, prediction_test_BIO,\n",
        "   #                                                average='weighted', labels=class_label)))"
      ],
      "metadata": {
        "id": "JfQMh28ggOYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eli5.show_weights(ner_crf_model_gaz, top=30)"
      ],
      "metadata": {
        "id": "CbwitbOfgP-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eli5.show_weights(ner_crf_model_gaz, top=10, feature_re='^ORG',\n",
        "#                  horizontal_layout=False, show=['targets'])"
      ],
      "metadata": {
        "id": "ob19NGAruyW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting the model with also POS tags"
      ],
      "metadata": {
        "id": "iTPlai-0O14n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the training dataset in the one required for training the model to\n",
        "# perform the named entity recognition task through the conditional random \n",
        "# fields method, here it is considered also whether a word, or sequence of words,\n",
        "# is in the set of known entities. The features in this section include also the\n",
        "# part-of-speech tags\n",
        "sentences_features_merged_train_BIO_gaz_pos = transform_sentences_to_features(sentences_merged_train_BIO,\n",
        "                                                                          postags = get_pos_tags_file(),\n",
        "                                                                          previous_words_to_embed=3, \n",
        "                                                                          next_words_to_embed=3,\n",
        "                                                                          gazetteer = gazetteer_dict,\n",
        "                                                                          gazetteer_entity_lenght = 6)\n",
        "\n",
        "# Converting the test dataset in the one required for test the model to perform\n",
        "# the named entity recognition task through the conditional random fields method,\n",
        "# here it is considered also whether a word, or sequence of words, is in the set\n",
        "# of known entities. The features in this section include also the \n",
        "# part-of-speech tags\n",
        "sentences_features_merged_test_BIO_gaz_pos = transform_sentences_to_features(sentences_merged_test_BIO,\n",
        "                                                                             postags = get_pos_tags_file(train_or_test=False),\n",
        "                                                                             previous_words_to_embed=3,\n",
        "                                                                             next_words_to_embed=3,\n",
        "                                                                             gazetteer = gazetteer_dict,\n",
        "                                                                             gazetteer_entity_lenght = 6)"
      ],
      "metadata": {
        "id": "8M_p5xdGxGor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the CRF model for NER\n",
        "ner_crf_model_gaz_pos = CRF(algorithm='lbfgs',\n",
        "                        c1=0.1,\n",
        "                        c2=0.1,\n",
        "                        max_iterations=150,\n",
        "                        verbose=True,\n",
        "                        all_possible_transitions=False)\n",
        "\n",
        "# Fitting the CRF model using the training set\n",
        "ner_crf_model_gaz_pos.fit(sentences_features_merged_train_BIO_gaz_pos, labels_merged_train_BIO)"
      ],
      "metadata": {
        "id": "zibis_XCxI6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the labels on which the performance evaluation has to be done\n",
        "classes_BIO_gaz_pos = list(ner_crf_model_gaz_pos.classes_)\n",
        "# Removing the class of words that are not entities in order to have the \n",
        "# evaluation of the performance considering only the classes of the entities\n",
        "classes_BIO_gaz_pos.remove('O')"
      ],
      "metadata": {
        "id": "VGUKJqOdaq5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the lables on the train set\n",
        "prediction_merged_train_BIO_gaz_pos = ner_crf_model_gaz_pos.predict(sentences_features_merged_train_BIO_gaz_pos)\n",
        "# Predicting the lables on the test set\n",
        "prediction_merged_test_BIO_gaz_pos = ner_crf_model_gaz_pos.predict(sentences_features_merged_test_BIO_gaz_pos)\n",
        "\n",
        "# Computing the flat F1 score on the train set\n",
        "f1_score_train_BIO_gaz_pos = crf_met.flat_f1_score(labels_merged_train_BIO, prediction_merged_train_BIO_gaz_pos,\n",
        "                                       average='weighted', labels=classes_BIO_gaz_pos)\n",
        "# Computing the flat F1 score on the test set\n",
        "f1_score_test_BIO_gaz_pos = crf_met.flat_f1_score(labels_merged_test_BIO, prediction_merged_test_BIO_gaz_pos,\n",
        "                                      average='weighted', labels=classes_BIO_gaz_pos)\n",
        "\n",
        "print('Flat F1 score on the trainset: ' + str(f1_score_train_BIO_gaz_pos))\n",
        "print('Flat F1 score on the testset: ' + str(f1_score_test_BIO_gaz_pos))"
      ],
      "metadata": {
        "id": "R4dHb7cZAFcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Performance on the trainset')\n",
        "performance_merged_train_BIO_gaz_pos = performance_metrics(prediction_merged_train_BIO_gaz_pos, labels_merged_train_BIO)\n",
        "performance_merged_train_BIO_gaz_pos"
      ],
      "metadata": {
        "id": "hfBXsnF4bHLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Performance on the testset')\n",
        "performance_merged_test_BIO_gaz_pos = performance_metrics(prediction_merged_test_BIO_gaz_pos, labels_merged_test_BIO)\n",
        "performance_merged_test_BIO_gaz_pos"
      ],
      "metadata": {
        "id": "GV2h-XsfbHRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here maybe, I'm not sure"
      ],
      "metadata": {
        "id": "dDSUdb4ZbVDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation\n",
        "param_grid = {\n",
        "    'c1': [0.1, 1.0, 10.0],\n",
        "    'c2': [0.1, 1.0, 10.0],\n",
        "    'min_freq': [1, 5, 10],\n",
        "    'max_iteration': [100, 500],\n",
        "    'all_possible_transitions': [False]\n",
        "}"
      ],
      "metadata": {
        "id": "s5_lBkb6JE0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "ner_crf_model_gaz_pos = CRF()\n",
        "crf_cv = GridSearchCV(ner_crf_model_gaz_pos, param_grid=param_grid, cv=5)\n",
        "crf_cv.fit(sentences_features_train_gaz_pos, labels_train)\n",
        "\n",
        "print('Best parameters: ', crf_cv.best_params_)\n",
        "print('Best score: ', crf_cv.best_score_)\n",
        "best_parameters = crf_cv.best_params_"
      ],
      "metadata": {
        "id": "PZH9gOuaKSM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the CRF model for NER\n",
        "ner_crf_model_gaz_pos = CRF(algorithm='lbfgs',\n",
        "                        c1=best_parameters['c1'],\n",
        "                        c2=best_parameters['c2'],\n",
        "                        min_freq=best_parameters['min_freq'],\n",
        "                        max_iterations=best_parameters['max_iteration'],\n",
        "                        verbose=True,\n",
        "                        all_possible_transitions=False)"
      ],
      "metadata": {
        "id": "C0Fs8-cYLSgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eli5.show_weights(ner_crf_model_gaz_pos, top=30)"
      ],
      "metadata": {
        "id": "ew5jAVSY-Xo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting the model with also embeddings representation of the words"
      ],
      "metadata": {
        "id": "WCuMssv9yT-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the dataset in the one required for executing applying the named\n",
        "# entity recognition through the conditional random fields method\n",
        "sentences_features_emb = transform_sentences_to_features(sentences, embeddings = ) # TODO\n",
        "sentences_features_emb[0:1]"
      ],
      "metadata": {
        "id": "-zpj972wya_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the CRF model for NER\n",
        "ner_crf_model_emb = CRF(c1=0.1, c2=0.1, max_iterations=100,  all_possible_transitions=False)\n",
        "\n",
        "# Fitting the CRF model using the training set\n",
        "ner_crf_model.fit(sentences_features_emb, labels)"
      ],
      "metadata": {
        "id": "P5YCPHYCybBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting the model using the data with only the inside-outside notation"
      ],
      "metadata": {
        "id": "Db99sXL081Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the sentences and the labels from the training dataset\n",
        "sentences_merged_train_IO, labels_merged_train_IO, _ = get_all_sentences_from_datasets(datasets_train_dict_IO, lower=False)\n",
        "# Getting the sentences and the labels from the test dataset\n",
        "sentences_merged_test_IO, labels_merged_test_IO, _ = get_all_sentences_from_datasets(datasets_test_dict_IO, lower=False)"
      ],
      "metadata": {
        "id": "rnbuRsU79DyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the training dataset without BIO notation in the format required\n",
        "# for training the model to perform the named entity recognition task through \n",
        "# the conditional random fields method, here it is considered also whether a word,\n",
        "# or sequence of words, is in the set of known entities. The features in this \n",
        "# section include also the part-of-speech tags.\n",
        "sentences_features_merged_train_IO_gaz_pos = transform_sentences_to_features(sentences_merged_train_IO,\n",
        "                                                                          postags = get_pos_tags_file(),\n",
        "                                                                          previous_words_to_embed=3, \n",
        "                                                                          next_words_to_embed=3,\n",
        "                                                                          gazetteer = gazetteer_dict,\n",
        "                                                                          gazetteer_entity_lenght = 6)\n",
        "\n",
        "# Converting the test dataset without BIO notation in the format required for\n",
        "# test the model to perform the named entity recognition task through the \n",
        "# conditional random fields method, here it is considered also whether a word,\n",
        "# or sequence of words, is in the set of known entities. The features in this \n",
        "# section include also the part-of-speech tags.\n",
        "sentences_features_merged_test_IO_gaz_pos = transform_sentences_to_features(sentences_merged_test_IO,\n",
        "                                                                             postags = get_pos_tags_file(train_or_test=False),\n",
        "                                                                             previous_words_to_embed=3,\n",
        "                                                                             next_words_to_embed=3,\n",
        "                                                                             gazetteer = gazetteer_dict,\n",
        "                                                                             gazetteer_entity_lenght = 6)"
      ],
      "metadata": {
        "id": "9otyACKr9D5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the CRF model for NER\n",
        "ner_crf_model_IO_gaz_pos = CRF(algorithm='lbfgs',\n",
        "                        c1=0.1,\n",
        "                        c2=0.1,\n",
        "                        max_iterations=100,\n",
        "                        verbose=True,\n",
        "                        all_possible_transitions=False)\n",
        "\n",
        "# Fitting the CRF model using the training set\n",
        "ner_crf_model_IO_gaz_pos.fit(sentences_features_merged_train_IO_gaz_pos, labels_merged_train_IO)"
      ],
      "metadata": {
        "id": "SCLSiaJtQ5yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the labels on which the performance evaluation has to be done\n",
        "classes_IO_gaz_pos = list(ner_crf_model_IO_gaz_pos.classes_)\n",
        "# Removing the class of words that are not entities in order to have the \n",
        "# evaluation of the performance considering only the classes of the entities\n",
        "classes_IO_gaz_pos.remove('O')"
      ],
      "metadata": {
        "id": "Byptwoy0dkeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the lables on the train set\n",
        "prediction_merged_train_IO_gaz_pos = ner_crf_model_IO_gaz_pos.predict(sentences_features_merged_train_IO_gaz_pos)\n",
        "# Predicting the lables on the test set\n",
        "prediction_merged_test_IO_gaz_pos = ner_crf_model_IO_gaz_pos.predict(sentences_features_merged_test_IO_gaz_pos)\n",
        "\n",
        "# Computing the flat F1 score on the train set\n",
        "f1_score_train_IO_gaz_pos = crf_met.flat_f1_score(labels_merged_train_IO, prediction_merged_train_IO_gaz_pos,\n",
        "                                       average='weighted', labels=classes_IO_gaz_pos)\n",
        "# Computing the flat F1 score on the test set\n",
        "f1_score_test_IO_gaz_pos = crf_met.flat_f1_score(labels_merged_test_IO, prediction_merged_test_IO_gaz_pos,\n",
        "                                      average='weighted', labels=classes_IO_gaz_pos)\n",
        "\n",
        "print('Flat F1 score on the trainset: ' + str(f1_score_train_IO_gaz_pos))\n",
        "print('Flat F1 score on the testset: ' + str(f1_score_test_IO_gaz_pos))"
      ],
      "metadata": {
        "id": "o78s9gfbUoWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Performance on the trainset')\n",
        "performance_merged_train_IO_gaz_pos = performance_metrics(prediction_merged_train_IO_gaz_pos, labels_merged_train_IO)\n",
        "performance_merged_train_IO_gaz_pos"
      ],
      "metadata": {
        "id": "4hMtWkMuQ54L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Performance on the testset')\n",
        "performance_merged_test_IO_gaz_pos = performance_metrics(prediction_merged_test_IO_gaz_pos, labels_merged_test_IO)\n",
        "performance_merged_test_IO_gaz_pos"
      ],
      "metadata": {
        "id": "ENpSuYPDUkql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eli5.show_weights(ner_crf_model_gaz_pos, top=30)"
      ],
      "metadata": {
        "id": "UP0jFz8dUktU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "dataset_names_train_BIO = ['degasperi_train_BIO.tsv', 'fiction_train_BIO.tsv','moro_train_BIO.tsv', 'wikinews_train_BIO.tsv']\n",
        "dataset_names_test_BIO = ['degasperi_test_BIO.tsv', 'fiction_test_BIO.tsv','moro_test_BIO.tsv', 'wikinews_test_BIO.tsv']\n",
        "\n",
        "def generate_unordered_tuples(s, limit=10000000):\n",
        "    # Convert set to list to ensure consistent ordering\n",
        "    elements = list(s)\n",
        "    n = len(elements)\n",
        "\n",
        "    # Generate tuples of different lengths from 0 to n\n",
        "    tuples = []\n",
        "    for r in range(1, min(n + 1, limit)):\n",
        "        tuples.extend(combinations(elements, r))\n",
        "\n",
        "    \n",
        "    return tuples\n",
        "\n",
        "#################################################################################################################\n",
        "\n",
        "def extract_sentence_labels(datasets_train_dict_BIO, datasets_test_dict_BIO):\n",
        "    # Getting the sentences and the labels from the training dataset\n",
        "    sentences_train, labels_train, _ = get_all_sentences_from_datasets(datasets_train_dict_BIO, lower=False)\n",
        "    # Getting the sentences and the labels from the test dataset\n",
        "    sentences_test, labels_test, _ = get_all_sentences_from_datasets(datasets_test_dict_BIO, lower=False)\n",
        "\n",
        "    return sentences_train, labels_train, sentences_test, labels_test\n",
        "\n",
        "#################################################################################################################\n",
        "\n",
        "# Definition of a gazetteer set\n",
        "PATH_TO_GAZETTEER = '/content/KIND_project/datasets/Entities'\n",
        "gazetteer_loc = set(line.replace('LOC','').strip() for line in open(PATH_TO_GAZETTEER + '/it-LOC-wikipedia.txt', encoding='utf-8'))\n",
        "gazetteer_org = set(line.replace('ORG','').strip() for line in open(PATH_TO_GAZETTEER + '/it-ORG-wikipedia.txt', encoding='utf-8'))\n",
        "gazetteer_per = set(line.replace('PER','').strip() for line in open(PATH_TO_GAZETTEER + '/it-PER-wikipedia.txt', encoding='utf-8'))\n",
        "gazetteer_dict = {\n",
        "    'LOC': gazetteer_loc,\n",
        "    'ORG': gazetteer_org,\n",
        "    'PER': gazetteer_per,\n",
        "}\n",
        "gazetteer = gazetteer_loc.union(gazetteer_org).union(gazetteer_per)\n",
        "\n",
        "#################################################################################################################\n",
        "\n",
        "# le altre abbiamo detto che non servono\n",
        "\n",
        "###################################################################################################################\n",
        "##soloquesta\n",
        "\n",
        "def get_CRF_POSandGazetters_model(sentences_train, labels_train, sentences_test): \n",
        "    # Converting the training dataset in the one required for training the model to\n",
        "    # perform the named entity recognition task through the conditional random \n",
        "    # fields method\n",
        "    sentences_features_train_gaz_pos = transform_sentences_to_features(sentences_train, postags = get_pos_tags(sentences_train), gazetteer = gazetteer_dict)\n",
        "\n",
        "    # Converting the test dataset in the one required for performing the named \n",
        "    # entity recognition task through the conditional random fields method\n",
        "    sentences_features_test_gaz_pos = transform_sentences_to_features(sentences_test, postags = get_pos_tags(sentences_test), gazetteer = gazetteer_dict)\n",
        "\n",
        "    sentences_features_train_gaz_pos[0]\n",
        "\n",
        "    #Creating the CRF model for NER\n",
        "    ner_crf_model_gaz_pos = CRF(algorithm='lbfgs',\n",
        "                            c1=0.5,\n",
        "                            c2=0.5,\n",
        "                            max_iterations=100,\n",
        "                            verbose=True,\n",
        "                            all_possible_transitions=False)\n",
        "\n",
        "    # Fitting the CRF model using the training set\n",
        "    ner_crf_model_gaz_pos.fit(sentences_features_train_gaz_pos, labels_train)\n",
        "\n",
        "    return ner_crf_model_gaz_pos, sentences_features_train_gaz_pos, sentences_features_test_gaz_pos\n",
        "\n",
        "def predict_and_evaluate(sentences_features_train_gaz_pos, sentences_features_test_gaz_pos, labels_train, labels_test, ner_crf_model_gaz_pos):\n",
        "    # Predicting the lables on the train set\n",
        "    prediction_train_BIO = ner_crf_model_gaz_pos.predict(sentences_features_train_gaz_pos)\n",
        "\n",
        "    # Predicting the lables on the test set\n",
        "    prediction_test_BIO = ner_crf_model_gaz_pos.predict(sentences_features_test_gaz_pos)\n",
        "\n",
        "    ###\n",
        "    # in qualche modo qui calcolo le performance varie e le salvo da qualche parte\n",
        "    ###\n",
        "\n",
        "    eli5.show_weights(ner_crf_model_gaz_pos, top=30)\n",
        "\n",
        "    performance_train = performance_metrics(prediction_train_BIO, labels_train)\n",
        "\n",
        "    performance_test = performance_metrics(prediction_test_BIO, labels_test)\n",
        "\n",
        "    return performance_train, performance_test\n",
        "\n",
        "#################################################################################################################\n",
        "\n",
        "def performance_metrics(predicted_labels, real_labels):\n",
        "  '''\n",
        "  Computes performance metrics given the predictions and the true labels\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  predictions: ndarray\n",
        "    predictions of samples obtained with a model\n",
        "  true_labels: ndarray\n",
        "    true labels of the samples\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  metrics_df: DataFrame\n",
        "    DataFrame containing the statistics contained in the parameter metrics_df\n",
        "    plus the statistics computed on the new predictions\n",
        "\n",
        "  '''\n",
        "  \n",
        "  metrics_df = None\n",
        "  classes = set(element for sentence in real_labels for element in sentence)\n",
        "  for tag in classes:\n",
        "    new_predicted_labels = np.array([1 if element == tag else 0 for sentence in predicted_labels for element in sentence])\n",
        "    new_real_labels = np.array([1 if element == tag else 0 for sentence in real_labels for element in sentence])\n",
        "    metrics_df = metrics(new_predicted_labels, new_real_labels, metrics_df=metrics_df, class_label=tag)\n",
        "  \n",
        "  return metrics_df\n",
        "\n",
        "#################################################################################################################\n",
        "\n",
        "  \n",
        "\n",
        "subsets_dataset_names_train_BIO = generate_unordered_tuples(set(dataset_names_train_BIO))\n",
        "subsets_dataset_names_test_BIO = generate_unordered_tuples(set(dataset_names_test_BIO))\n",
        "\n",
        "\n",
        "print(subsets_dataset_names_train_BIO)\n",
        "print(subsets_dataset_names_test_BIO)\n",
        "\n",
        "\n",
        "subsets_datasets_train_dict_BIO = []\n",
        "subsets_datasets_test_dict_BIO = []\n",
        "\n",
        "for i in range(0, len(subsets_dataset_names_train_BIO)):\n",
        "    current_subset_train_dict = {}\n",
        "    current_subset_test_dict = {}\n",
        "    for j in range(0, len(subsets_dataset_names_train_BIO[i])):\n",
        "      current_subset_train_dict[subsets_dataset_names_train_BIO[i][j]] = datasets_train_dict_BIO[subsets_dataset_names_train_BIO[i][j]]\n",
        "      current_subset_test_dict[subsets_dataset_names_test_BIO[i][j]] = datasets_test_dict_BIO[subsets_dataset_names_test_BIO[i][j]]\n",
        "    #current_subset_test_dict['dataset_name'] = subsets_dataset_names_test_BIO[i]\n",
        "    #current_subset_train_dict['dataset_name'] = subsets_dataset_names_train_BIO[i]\n",
        "    subsets_datasets_train_dict_BIO.append(current_subset_train_dict)\n",
        "    subsets_datasets_test_dict_BIO.append(current_subset_test_dict)\n",
        "\n",
        "\n",
        "print(len(subsets_datasets_train_dict_BIO))\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(subsets_datasets_train_dict_BIO)):\n",
        "    print('#'*30 + ' ' + str(i) + ' ' + '#'*30)\n",
        "    sentences_train, labels_train, sentences_test, labels_test = extract_sentence_labels(subsets_datasets_train_dict_BIO[i], subsets_datasets_test_dict_BIO[i])\n",
        "\n",
        "    ner_crf_model_gaz_pos, sentences_features_train_gaz_pos, sentences_features_test_gaz_pos = get_CRF_POSandGazetters_model(sentences_train, labels_train, sentences_test)\n",
        "\n",
        "    res_train, res_test = predict_and_evaluate(sentences_features_train_gaz_pos, \n",
        "                                                    sentences_features_test_gaz_pos, \n",
        "                                                    labels_train, \n",
        "                                                    labels_test, \n",
        "                                                    ner_crf_model_gaz_pos)\n",
        "                                                    #subsets_datasets_train_dict_BIO[i]['dataset_name'].replace('_train.tsv', '')))\n",
        "    results.append({'dataset_name': str(subsets_dataset_names_train_BIO[i]).replace('_train_BIO.tsv', '').replace('(', '').replace(')', '').replace(',', '+').replace(\"'\", \"\"),\n",
        "                    'results_train': res_train,\n",
        "                    'results_test': res_test\n",
        "                    })\n",
        "import pickle    \n",
        "with open('data.pkl', 'wb') as file:\n",
        "    pickle.dump(results, file)\n",
        "\n",
        "with open('data.pkl', 'rb') as file:\n",
        "    loaded_variable = pickle.load(file)\n",
        "\n",
        "print(loaded_variable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYOh9fVoSThf",
        "outputId": "83179e9c-affc-4de8-9171-3c35baf12cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('wikinews_train_BIO.tsv',), ('degasperi_train_BIO.tsv',), ('fiction_train_BIO.tsv',), ('moro_train_BIO.tsv',), ('wikinews_train_BIO.tsv', 'degasperi_train_BIO.tsv'), ('wikinews_train_BIO.tsv', 'fiction_train_BIO.tsv'), ('wikinews_train_BIO.tsv', 'moro_train_BIO.tsv'), ('degasperi_train_BIO.tsv', 'fiction_train_BIO.tsv'), ('degasperi_train_BIO.tsv', 'moro_train_BIO.tsv'), ('fiction_train_BIO.tsv', 'moro_train_BIO.tsv'), ('wikinews_train_BIO.tsv', 'degasperi_train_BIO.tsv', 'fiction_train_BIO.tsv'), ('wikinews_train_BIO.tsv', 'degasperi_train_BIO.tsv', 'moro_train_BIO.tsv'), ('wikinews_train_BIO.tsv', 'fiction_train_BIO.tsv', 'moro_train_BIO.tsv'), ('degasperi_train_BIO.tsv', 'fiction_train_BIO.tsv', 'moro_train_BIO.tsv'), ('wikinews_train_BIO.tsv', 'degasperi_train_BIO.tsv', 'fiction_train_BIO.tsv', 'moro_train_BIO.tsv')]\n",
            "[('fiction_test_BIO.tsv',), ('moro_test_BIO.tsv',), ('wikinews_test_BIO.tsv',), ('degasperi_test_BIO.tsv',), ('fiction_test_BIO.tsv', 'moro_test_BIO.tsv'), ('fiction_test_BIO.tsv', 'wikinews_test_BIO.tsv'), ('fiction_test_BIO.tsv', 'degasperi_test_BIO.tsv'), ('moro_test_BIO.tsv', 'wikinews_test_BIO.tsv'), ('moro_test_BIO.tsv', 'degasperi_test_BIO.tsv'), ('wikinews_test_BIO.tsv', 'degasperi_test_BIO.tsv'), ('fiction_test_BIO.tsv', 'moro_test_BIO.tsv', 'wikinews_test_BIO.tsv'), ('fiction_test_BIO.tsv', 'moro_test_BIO.tsv', 'degasperi_test_BIO.tsv'), ('fiction_test_BIO.tsv', 'wikinews_test_BIO.tsv', 'degasperi_test_BIO.tsv'), ('moro_test_BIO.tsv', 'wikinews_test_BIO.tsv', 'degasperi_test_BIO.tsv'), ('fiction_test_BIO.tsv', 'moro_test_BIO.tsv', 'wikinews_test_BIO.tsv', 'degasperi_test_BIO.tsv')]\n",
            "15\n",
            "############################## 0 ##############################\n",
            "Converting the DataFrame of the datasetwikinews_train_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "249077it [00:13, 18009.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7522/7522 [00:00<00:00, 1691393.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetfiction_test_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21506it [00:01, 20064.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 807/807 [00:00<00:00, 815811.84it/s]\n",
            "7489it [00:04, 1618.67it/s]\n",
            "794it [00:00, 2267.78it/s]\n",
            "loading training data to CRFsuite: 100%|██████████| 7489/7489 [00:04<00:00, 1757.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 0\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 184712\n",
            "Seconds required: 0.785\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.500000\n",
            "c2: 0.500000\n",
            "num_memories: 6\n",
            "max_iterations: 100\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=0.95  loss=282153.66 active=178890 feature_norm=0.25\n",
            "Iter 2   time=0.25  loss=263706.52 active=129176 feature_norm=0.22\n",
            "Iter 3   time=0.70  loss=211087.07 active=113666 feature_norm=0.13\n",
            "Iter 4   time=0.48  loss=207916.95 active=113943 feature_norm=0.12\n",
            "Iter 5   time=0.24  loss=206559.17 active=119110 feature_norm=0.12\n",
            "Iter 6   time=0.24  loss=201771.63 active=118397 feature_norm=0.17\n",
            "Iter 7   time=0.23  loss=193691.78 active=115448 feature_norm=0.25\n",
            "Iter 8   time=0.47  loss=162136.13 active=112837 feature_norm=1.73\n",
            "Iter 9   time=0.24  loss=161526.47 active=115770 feature_norm=1.76\n",
            "Iter 10  time=0.25  loss=133031.57 active=119887 feature_norm=1.66\n",
            "Iter 11  time=0.72  loss=126594.73 active=117206 feature_norm=1.90\n",
            "Iter 12  time=0.24  loss=118290.56 active=118652 feature_norm=1.90\n",
            "Iter 13  time=0.24  loss=111839.59 active=118698 feature_norm=2.07\n",
            "Iter 14  time=0.71  loss=103734.81 active=117222 feature_norm=2.38\n",
            "Iter 15  time=0.24  loss=101879.97 active=117681 feature_norm=2.38\n",
            "Iter 16  time=0.23  loss=99266.96 active=117683 feature_norm=2.41\n",
            "Iter 17  time=0.23  loss=97806.25 active=118278 feature_norm=2.54\n",
            "Iter 18  time=0.24  loss=96657.19 active=118173 feature_norm=2.62\n",
            "Iter 19  time=0.24  loss=92937.50 active=118228 feature_norm=2.82\n",
            "Iter 20  time=0.24  loss=91772.55 active=118329 feature_norm=2.89\n",
            "Iter 21  time=0.26  loss=88425.32 active=118398 feature_norm=3.00\n",
            "Iter 22  time=0.24  loss=87552.39 active=118732 feature_norm=3.05\n",
            "Iter 23  time=0.25  loss=85609.68 active=119543 feature_norm=3.12\n",
            "Iter 24  time=0.24  loss=83885.08 active=119431 feature_norm=3.23\n",
            "Iter 25  time=0.25  loss=80858.39 active=119895 feature_norm=3.49\n",
            "Iter 26  time=0.24  loss=78238.93 active=112751 feature_norm=3.74\n",
            "Iter 27  time=0.24  loss=73819.35 active=101494 feature_norm=4.13\n",
            "Iter 28  time=0.24  loss=71630.35 active=90242 feature_norm=4.51\n",
            "Iter 29  time=0.24  loss=68489.54 active=92002 feature_norm=4.87\n",
            "Iter 30  time=0.23  loss=65657.65 active=90936 feature_norm=5.45\n",
            "Iter 31  time=0.25  loss=62089.84 active=89071 feature_norm=6.03\n",
            "Iter 32  time=0.24  loss=58830.70 active=88349 feature_norm=7.05\n",
            "Iter 33  time=0.24  loss=55952.31 active=87497 feature_norm=8.13\n",
            "Iter 34  time=0.24  loss=52935.23 active=87070 feature_norm=8.98\n",
            "Iter 35  time=0.24  loss=45407.22 active=85261 feature_norm=12.57\n",
            "Iter 36  time=0.71  loss=44966.19 active=83651 feature_norm=14.07\n",
            "Iter 37  time=0.24  loss=41569.17 active=83520 feature_norm=15.53\n",
            "Iter 38  time=0.25  loss=39328.65 active=82646 feature_norm=16.66\n",
            "Iter 39  time=0.24  loss=36513.67 active=77020 feature_norm=20.06\n",
            "Iter 40  time=0.25  loss=33864.18 active=76273 feature_norm=23.07\n",
            "Iter 41  time=0.24  loss=32928.79 active=75371 feature_norm=23.26\n",
            "Iter 42  time=0.25  loss=31267.26 active=73819 feature_norm=23.59\n",
            "Iter 43  time=0.24  loss=29878.06 active=72697 feature_norm=24.45\n",
            "Iter 44  time=0.24  loss=29220.25 active=67855 feature_norm=26.79\n",
            "Iter 45  time=0.25  loss=27927.48 active=68550 feature_norm=27.00\n",
            "Iter 46  time=0.25  loss=27565.81 active=68227 feature_norm=27.27\n",
            "Iter 47  time=0.25  loss=26268.45 active=59281 feature_norm=29.48\n",
            "Iter 48  time=0.25  loss=25666.26 active=59047 feature_norm=29.87\n",
            "Iter 49  time=0.26  loss=25154.31 active=58208 feature_norm=30.46\n",
            "Iter 50  time=0.24  loss=24129.43 active=56446 feature_norm=32.43\n",
            "Iter 51  time=0.49  loss=23652.72 active=56448 feature_norm=32.97\n",
            "Iter 52  time=0.24  loss=23080.95 active=55618 feature_norm=33.62\n",
            "Iter 53  time=0.24  loss=22098.05 active=53326 feature_norm=36.25\n",
            "Iter 54  time=0.25  loss=21299.24 active=50336 feature_norm=39.63\n",
            "Iter 55  time=0.25  loss=20633.65 active=49990 feature_norm=41.25\n",
            "Iter 56  time=0.25  loss=20130.55 active=49035 feature_norm=43.32\n",
            "Iter 57  time=0.25  loss=19362.24 active=47608 feature_norm=45.61\n",
            "Iter 58  time=0.24  loss=18713.49 active=45844 feature_norm=47.68\n",
            "Iter 59  time=0.24  loss=18249.48 active=44747 feature_norm=48.96\n",
            "Iter 60  time=0.23  loss=17853.64 active=44388 feature_norm=50.84\n",
            "Iter 61  time=0.24  loss=17479.27 active=43916 feature_norm=52.54\n",
            "Iter 62  time=0.25  loss=17217.82 active=42181 feature_norm=57.31\n",
            "Iter 63  time=0.24  loss=16906.10 active=42189 feature_norm=57.85\n",
            "Iter 64  time=0.27  loss=16808.54 active=42083 feature_norm=58.27\n",
            "Iter 65  time=0.25  loss=16573.42 active=41556 feature_norm=59.73\n",
            "Iter 66  time=0.25  loss=16434.51 active=39802 feature_norm=61.29\n",
            "Iter 67  time=0.25  loss=16233.04 active=39989 feature_norm=61.25\n",
            "Iter 68  time=0.26  loss=16168.30 active=39962 feature_norm=61.76\n",
            "Iter 69  time=0.26  loss=16101.84 active=38982 feature_norm=62.34\n",
            "Iter 70  time=0.25  loss=16047.69 active=38780 feature_norm=62.49\n",
            "Iter 71  time=0.26  loss=15944.66 active=38128 feature_norm=63.47\n",
            "Iter 72  time=0.24  loss=15870.70 active=37762 feature_norm=63.62\n",
            "Iter 73  time=0.25  loss=15801.90 active=37187 feature_norm=63.73\n",
            "Iter 74  time=0.25  loss=15703.18 active=35751 feature_norm=63.65\n",
            "Iter 75  time=0.24  loss=15623.07 active=34646 feature_norm=63.80\n",
            "Iter 76  time=0.25  loss=15550.36 active=34088 feature_norm=63.90\n",
            "Iter 77  time=0.25  loss=15441.85 active=33209 feature_norm=64.24\n",
            "Iter 78  time=0.24  loss=15344.16 active=32682 feature_norm=64.39\n",
            "Iter 79  time=0.24  loss=15242.38 active=32363 feature_norm=64.59\n",
            "Iter 80  time=0.25  loss=15149.87 active=31365 feature_norm=64.63\n",
            "Iter 81  time=0.24  loss=15059.69 active=31265 feature_norm=64.81\n",
            "Iter 82  time=0.24  loss=14977.54 active=31106 feature_norm=64.84\n",
            "Iter 83  time=0.25  loss=14899.72 active=31029 feature_norm=64.86\n",
            "Iter 84  time=0.25  loss=14798.60 active=30863 feature_norm=64.87\n",
            "Iter 85  time=0.24  loss=14709.31 active=30426 feature_norm=64.99\n",
            "Iter 86  time=0.25  loss=14644.75 active=30224 feature_norm=65.13\n",
            "Iter 87  time=0.24  loss=14583.49 active=30143 feature_norm=65.34\n",
            "Iter 88  time=0.24  loss=14530.10 active=30046 feature_norm=65.43\n",
            "Iter 89  time=0.25  loss=14488.92 active=29937 feature_norm=65.53\n",
            "Iter 90  time=0.25  loss=14430.29 active=29739 feature_norm=65.65\n",
            "Iter 91  time=0.25  loss=14389.08 active=29450 feature_norm=65.84\n",
            "Iter 92  time=0.24  loss=14331.24 active=29369 feature_norm=65.93\n",
            "Iter 93  time=0.24  loss=14301.74 active=29300 feature_norm=65.98\n",
            "Iter 94  time=0.24  loss=14264.59 active=29204 feature_norm=65.99\n",
            "Iter 95  time=0.25  loss=14233.90 active=29113 feature_norm=66.03\n",
            "Iter 96  time=0.24  loss=14198.27 active=28964 feature_norm=65.99\n",
            "Iter 97  time=0.25  loss=14166.24 active=28899 feature_norm=65.98\n",
            "Iter 98  time=0.25  loss=14132.88 active=28722 feature_norm=65.95\n",
            "Iter 99  time=0.26  loss=14108.26 active=28620 feature_norm=65.94\n",
            "Iter 100 time=0.24  loss=14082.74 active=28450 feature_norm=65.90\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 27.758\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 28450 (184712)\n",
            "Number of active attributes: 21661 (161961)\n",
            "Number of active labels: 7 (7)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.019\n",
            "\n",
            "############################## 1 ##############################\n",
            "Converting the DataFrame of the datasetdegasperi_train_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "123504it [00:06, 19939.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3793/3793 [00:00<00:00, 1272923.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetmoro_test_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "82806it [00:04, 19468.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2203/2203 [00:00<00:00, 1178427.71it/s]\n",
            "3715it [00:02, 1792.82it/s]\n",
            "2196it [00:01, 1579.98it/s]\n",
            "loading training data to CRFsuite: 100%|██████████| 3715/3715 [00:02<00:00, 1823.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 0\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 93163\n",
            "Seconds required: 0.339\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.500000\n",
            "c2: 0.500000\n",
            "num_memories: 6\n",
            "max_iterations: 100\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=0.23  loss=178533.45 active=92201 feature_norm=1.00\n",
            "Iter 2   time=0.11  loss=171486.34 active=48575 feature_norm=0.96\n",
            "Iter 3   time=0.11  loss=118191.92 active=25577 feature_norm=2.43\n",
            "Iter 4   time=0.22  loss=87139.93 active=86037 feature_norm=2.47\n",
            "Iter 5   time=0.11  loss=81036.49 active=86055 feature_norm=2.81\n",
            "Iter 6   time=0.11  loss=41968.00 active=24829 feature_norm=28.67\n",
            "Iter 7   time=0.33  loss=39703.35 active=31555 feature_norm=28.74\n",
            "Iter 8   time=0.22  loss=27529.53 active=31781 feature_norm=16.50\n",
            "Iter 9   time=0.11  loss=23492.24 active=26273 feature_norm=10.93\n",
            "Iter 10  time=0.11  loss=22298.93 active=24278 feature_norm=15.93\n",
            "Iter 11  time=0.11  loss=21387.92 active=24089 feature_norm=15.54\n",
            "Iter 12  time=0.22  loss=20550.85 active=23828 feature_norm=14.47\n",
            "Iter 13  time=0.12  loss=20176.14 active=23694 feature_norm=14.79\n",
            "Iter 14  time=0.11  loss=19275.96 active=22859 feature_norm=16.24\n",
            "Iter 15  time=0.11  loss=18175.03 active=22697 feature_norm=16.91\n",
            "Iter 16  time=0.12  loss=16170.21 active=20833 feature_norm=18.85\n",
            "Iter 17  time=0.22  loss=15624.36 active=20600 feature_norm=19.90\n",
            "Iter 18  time=0.12  loss=14546.94 active=20603 feature_norm=20.80\n",
            "Iter 19  time=0.12  loss=13657.10 active=20304 feature_norm=21.91\n",
            "Iter 20  time=0.12  loss=12886.30 active=20066 feature_norm=22.52\n",
            "Iter 21  time=0.12  loss=12271.02 active=19767 feature_norm=23.77\n",
            "Iter 22  time=0.12  loss=11843.64 active=19588 feature_norm=25.21\n",
            "Iter 23  time=0.12  loss=11231.71 active=19491 feature_norm=25.76\n",
            "Iter 24  time=0.12  loss=10894.85 active=19431 feature_norm=26.70\n",
            "Iter 25  time=0.11  loss=10503.47 active=19245 feature_norm=28.21\n",
            "Iter 26  time=0.12  loss=9945.00  active=19257 feature_norm=29.26\n",
            "Iter 27  time=0.11  loss=9662.63  active=19123 feature_norm=30.25\n",
            "Iter 28  time=0.12  loss=9397.49  active=19167 feature_norm=30.76\n",
            "Iter 29  time=0.13  loss=9037.61  active=19026 feature_norm=31.80\n",
            "Iter 30  time=0.12  loss=8445.69  active=18393 feature_norm=33.85\n",
            "Iter 31  time=0.12  loss=8173.09  active=17968 feature_norm=34.75\n",
            "Iter 32  time=0.13  loss=7899.64  active=17831 feature_norm=35.10\n",
            "Iter 33  time=0.12  loss=7677.92  active=17512 feature_norm=35.60\n",
            "Iter 34  time=0.12  loss=7400.17  active=16500 feature_norm=36.13\n",
            "Iter 35  time=0.12  loss=7144.78  active=15478 feature_norm=36.67\n",
            "Iter 36  time=0.12  loss=6874.29  active=14087 feature_norm=37.33\n",
            "Iter 37  time=0.12  loss=6620.28  active=13150 feature_norm=38.96\n",
            "Iter 38  time=0.12  loss=6467.97  active=13069 feature_norm=39.27\n",
            "Iter 39  time=0.12  loss=6302.53  active=12834 feature_norm=39.74\n",
            "Iter 40  time=0.12  loss=6165.28  active=12555 feature_norm=40.01\n",
            "Iter 41  time=0.12  loss=5979.29  active=11832 feature_norm=40.87\n",
            "Iter 42  time=0.11  loss=5859.04  active=11648 feature_norm=40.85\n",
            "Iter 43  time=0.11  loss=5761.23  active=11528 feature_norm=41.02\n",
            "Iter 44  time=0.12  loss=5615.41  active=11186 feature_norm=40.98\n",
            "Iter 45  time=0.11  loss=5560.48  active=11239 feature_norm=40.73\n",
            "Iter 46  time=0.12  loss=5534.89  active=11225 feature_norm=40.74\n",
            "Iter 47  time=0.12  loss=5459.97  active=10698 feature_norm=40.52\n",
            "Iter 48  time=0.11  loss=5407.05  active=10657 feature_norm=40.31\n",
            "Iter 49  time=0.11  loss=5344.76  active=10402 feature_norm=40.08\n",
            "Iter 50  time=0.11  loss=5262.46  active=9832  feature_norm=39.81\n",
            "Iter 51  time=0.12  loss=5223.20  active=9702  feature_norm=39.77\n",
            "Iter 52  time=0.11  loss=5179.87  active=9672  feature_norm=39.69\n",
            "Iter 53  time=0.12  loss=5131.43  active=9620  feature_norm=39.66\n",
            "Iter 54  time=0.34  loss=5103.78  active=9541  feature_norm=39.67\n",
            "Iter 55  time=0.12  loss=5053.49  active=9267  feature_norm=39.71\n",
            "Iter 56  time=0.11  loss=5014.19  active=9245  feature_norm=39.79\n",
            "Iter 57  time=0.12  loss=4974.43  active=9143  feature_norm=39.79\n",
            "Iter 58  time=0.11  loss=4931.79  active=8951  feature_norm=39.91\n",
            "Iter 59  time=0.11  loss=4882.56  active=8827  feature_norm=39.90\n",
            "Iter 60  time=0.11  loss=4848.44  active=8781  feature_norm=39.92\n",
            "Iter 61  time=0.12  loss=4818.22  active=8692  feature_norm=39.92\n",
            "Iter 62  time=0.12  loss=4775.11  active=8571  feature_norm=39.89\n",
            "Iter 63  time=0.23  loss=4753.29  active=8460  feature_norm=39.89\n",
            "Iter 64  time=0.12  loss=4728.79  active=8389  feature_norm=39.83\n",
            "Iter 65  time=0.12  loss=4710.46  active=8379  feature_norm=39.82\n",
            "Iter 66  time=0.12  loss=4685.91  active=8321  feature_norm=39.74\n",
            "Iter 67  time=0.12  loss=4657.97  active=8181  feature_norm=39.64\n",
            "Iter 68  time=0.11  loss=4639.81  active=8143  feature_norm=39.54\n",
            "Iter 69  time=0.12  loss=4626.42  active=8113  feature_norm=39.51\n",
            "Iter 70  time=0.12  loss=4612.01  active=8049  feature_norm=39.44\n",
            "Iter 71  time=0.12  loss=4596.91  active=8005  feature_norm=39.41\n",
            "Iter 72  time=0.11  loss=4578.44  active=7915  feature_norm=39.31\n",
            "Iter 73  time=0.11  loss=4561.92  active=7924  feature_norm=39.29\n",
            "Iter 74  time=0.11  loss=4546.15  active=7872  feature_norm=39.21\n",
            "Iter 75  time=0.11  loss=4531.04  active=7826  feature_norm=39.22\n",
            "Iter 76  time=0.12  loss=4516.16  active=7756  feature_norm=39.16\n",
            "Iter 77  time=0.12  loss=4492.69  active=7633  feature_norm=39.10\n",
            "Iter 78  time=0.12  loss=4473.62  active=7541  feature_norm=39.01\n",
            "Iter 79  time=0.12  loss=4457.59  active=7532  feature_norm=39.00\n",
            "Iter 80  time=0.12  loss=4446.08  active=7491  feature_norm=38.94\n",
            "Iter 81  time=0.12  loss=4427.24  active=7485  feature_norm=38.94\n",
            "Iter 82  time=0.11  loss=4407.79  active=7423  feature_norm=38.85\n",
            "Iter 83  time=0.11  loss=4387.49  active=7345  feature_norm=38.81\n",
            "Iter 84  time=0.11  loss=4376.25  active=7315  feature_norm=38.72\n",
            "Iter 85  time=0.12  loss=4362.87  active=7343  feature_norm=38.70\n",
            "Iter 86  time=0.12  loss=4348.69  active=7328  feature_norm=38.64\n",
            "Iter 87  time=0.11  loss=4325.42  active=7203  feature_norm=38.59\n",
            "Iter 88  time=0.23  loss=4317.55  active=7200  feature_norm=38.55\n",
            "Iter 89  time=0.11  loss=4309.95  active=7189  feature_norm=38.56\n",
            "Iter 90  time=0.11  loss=4300.26  active=7212  feature_norm=38.58\n",
            "Iter 91  time=0.11  loss=4294.37  active=7183  feature_norm=38.60\n",
            "Iter 92  time=0.11  loss=4283.58  active=7158  feature_norm=38.62\n",
            "Iter 93  time=0.11  loss=4273.78  active=7137  feature_norm=38.63\n",
            "Iter 94  time=0.11  loss=4269.63  active=7114  feature_norm=38.64\n",
            "Iter 95  time=0.11  loss=4258.16  active=7108  feature_norm=38.67\n",
            "Iter 96  time=0.12  loss=4253.16  active=7102  feature_norm=38.69\n",
            "Iter 97  time=0.11  loss=4244.92  active=7101  feature_norm=38.70\n",
            "Iter 98  time=0.11  loss=4240.14  active=7100  feature_norm=38.73\n",
            "Iter 99  time=0.12  loss=4234.03  active=7084  feature_norm=38.74\n",
            "Iter 100 time=0.11  loss=4228.53  active=7065  feature_norm=38.77\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 12.775\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 7065 (93163)\n",
            "Number of active attributes: 4684 (87850)\n",
            "Number of active labels: 7 (7)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.005\n",
            "\n",
            "############################## 2 ##############################\n",
            "Converting the DataFrame of the datasetfiction_train_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "170942it [00:08, 19579.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7479/7479 [00:00<00:00, 1530130.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetwikinews_test_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "59220it [00:03, 19386.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1804/1804 [00:00<00:00, 989346.81it/s]\n",
            "7360it [00:02, 2596.86it/s]\n",
            "1801it [00:01, 1785.73it/s]\n",
            "loading training data to CRFsuite: 100%|██████████| 7360/7360 [00:02<00:00, 2716.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 0\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 112428\n",
            "Seconds required: 0.486\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.500000\n",
            "c2: 0.500000\n",
            "num_memories: 6\n",
            "max_iterations: 100\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=0.30  loss=118663.76 active=111448 feature_norm=1.00\n",
            "Iter 2   time=0.15  loss=115636.16 active=57728 feature_norm=0.98\n",
            "Iter 3   time=0.16  loss=26685.08 active=29035 feature_norm=2.72\n",
            "Iter 4   time=0.61  loss=26341.36 active=28100 feature_norm=2.71\n",
            "Iter 5   time=0.76  loss=26336.75 active=26435 feature_norm=2.66\n",
            "Iter 6   time=0.44  loss=25905.30 active=26821 feature_norm=2.79\n",
            "Iter 7   time=0.30  loss=25290.85 active=26711 feature_norm=2.86\n",
            "Iter 8   time=0.30  loss=25237.20 active=26275 feature_norm=2.96\n",
            "Iter 9   time=0.16  loss=24786.48 active=25742 feature_norm=3.00\n",
            "Iter 10  time=0.15  loss=24419.72 active=25050 feature_norm=3.08\n",
            "Iter 11  time=0.16  loss=23679.49 active=22604 feature_norm=4.00\n",
            "Iter 12  time=0.16  loss=19835.57 active=22439 feature_norm=5.19\n",
            "Iter 13  time=0.15  loss=17811.26 active=22266 feature_norm=5.76\n",
            "Iter 14  time=0.15  loss=15622.51 active=22398 feature_norm=6.72\n",
            "Iter 15  time=0.15  loss=14634.81 active=22115 feature_norm=7.58\n",
            "Iter 16  time=0.30  loss=14447.41 active=22259 feature_norm=8.10\n",
            "Iter 17  time=0.16  loss=14284.62 active=22257 feature_norm=8.08\n",
            "Iter 18  time=0.31  loss=13920.82 active=21912 feature_norm=7.45\n",
            "Iter 19  time=0.15  loss=13594.84 active=21857 feature_norm=7.99\n",
            "Iter 20  time=0.15  loss=12974.42 active=21349 feature_norm=8.89\n",
            "Iter 21  time=0.15  loss=11447.05 active=17896 feature_norm=11.07\n",
            "Iter 22  time=0.47  loss=11243.75 active=16991 feature_norm=11.57\n",
            "Iter 23  time=0.15  loss=11062.80 active=17063 feature_norm=11.54\n",
            "Iter 24  time=0.15  loss=10937.15 active=16369 feature_norm=11.76\n",
            "Iter 25  time=0.15  loss=10251.89 active=13711 feature_norm=14.15\n",
            "Iter 26  time=0.31  loss=9848.02  active=13580 feature_norm=15.04\n",
            "Iter 27  time=0.15  loss=9724.34  active=12804 feature_norm=16.36\n",
            "Iter 28  time=0.16  loss=8801.55  active=12478 feature_norm=18.91\n",
            "Iter 29  time=0.15  loss=8403.84  active=12489 feature_norm=20.11\n",
            "Iter 30  time=0.15  loss=8022.80  active=12276 feature_norm=21.20\n",
            "Iter 31  time=0.15  loss=7378.40  active=12063 feature_norm=25.28\n",
            "Iter 32  time=0.15  loss=7228.81  active=12304 feature_norm=25.17\n",
            "Iter 33  time=0.46  loss=7096.59  active=12262 feature_norm=25.09\n",
            "Iter 34  time=0.15  loss=6973.91  active=12204 feature_norm=24.63\n",
            "Iter 35  time=0.15  loss=6902.77  active=12046 feature_norm=24.78\n",
            "Iter 36  time=0.15  loss=6575.88  active=12023 feature_norm=25.68\n",
            "Iter 37  time=0.15  loss=6346.13  active=11857 feature_norm=26.03\n",
            "Iter 38  time=0.15  loss=5967.26  active=11045 feature_norm=27.40\n",
            "Iter 39  time=0.16  loss=5731.17  active=10426 feature_norm=29.20\n",
            "Iter 40  time=0.15  loss=5340.45  active=9903  feature_norm=30.83\n",
            "Iter 41  time=0.15  loss=5189.42  active=9780  feature_norm=31.28\n",
            "Iter 42  time=0.29  loss=5010.33  active=9437  feature_norm=31.23\n",
            "Iter 43  time=0.15  loss=4785.78  active=9127  feature_norm=32.23\n",
            "Iter 44  time=0.15  loss=4614.19  active=8987  feature_norm=32.93\n",
            "Iter 45  time=0.15  loss=4390.89  active=8787  feature_norm=34.22\n",
            "Iter 46  time=0.15  loss=4214.69  active=8474  feature_norm=34.94\n",
            "Iter 47  time=0.15  loss=4110.71  active=8407  feature_norm=35.26\n",
            "Iter 48  time=0.15  loss=3981.28  active=7893  feature_norm=35.76\n",
            "Iter 49  time=0.15  loss=3899.58  active=7789  feature_norm=36.00\n",
            "Iter 50  time=0.15  loss=3828.55  active=7674  feature_norm=36.41\n",
            "Iter 51  time=0.15  loss=3756.40  active=7375  feature_norm=36.72\n",
            "Iter 52  time=0.16  loss=3676.80  active=6999  feature_norm=37.01\n",
            "Iter 53  time=0.15  loss=3605.34  active=6885  feature_norm=37.31\n",
            "Iter 54  time=0.30  loss=3585.60  active=6867  feature_norm=37.29\n",
            "Iter 55  time=0.16  loss=3535.62  active=6512  feature_norm=37.59\n",
            "Iter 56  time=0.15  loss=3487.41  active=6378  feature_norm=37.97\n",
            "Iter 57  time=0.15  loss=3439.92  active=6296  feature_norm=38.16\n",
            "Iter 58  time=0.16  loss=3403.83  active=6153  feature_norm=38.27\n",
            "Iter 59  time=0.16  loss=3390.45  active=5898  feature_norm=38.03\n",
            "Iter 60  time=0.16  loss=3352.29  active=5929  feature_norm=38.14\n",
            "Iter 61  time=0.15  loss=3335.43  active=5893  feature_norm=38.19\n",
            "Iter 62  time=0.15  loss=3319.82  active=5874  feature_norm=38.20\n",
            "Iter 63  time=0.16  loss=3278.64  active=5753  feature_norm=38.09\n",
            "Iter 64  time=0.46  loss=3264.16  active=5711  feature_norm=38.12\n",
            "Iter 65  time=0.15  loss=3227.36  active=5651  feature_norm=38.06\n",
            "Iter 66  time=0.15  loss=3200.67  active=5543  feature_norm=38.04\n",
            "Iter 67  time=0.15  loss=3177.17  active=5478  feature_norm=38.02\n",
            "Iter 68  time=0.16  loss=3164.38  active=5460  feature_norm=38.00\n",
            "Iter 69  time=0.16  loss=3154.21  active=5407  feature_norm=37.97\n",
            "Iter 70  time=0.16  loss=3133.85  active=5270  feature_norm=37.98\n",
            "Iter 71  time=0.16  loss=3118.09  active=5190  feature_norm=38.05\n",
            "Iter 72  time=0.16  loss=3100.71  active=5125  feature_norm=38.08\n",
            "Iter 73  time=0.16  loss=3083.28  active=4992  feature_norm=38.18\n",
            "Iter 74  time=0.15  loss=3063.87  active=4886  feature_norm=38.28\n",
            "Iter 75  time=0.16  loss=3047.42  active=4821  feature_norm=38.31\n",
            "Iter 76  time=0.15  loss=3029.73  active=4785  feature_norm=38.28\n",
            "Iter 77  time=0.16  loss=3008.12  active=4740  feature_norm=38.14\n",
            "Iter 78  time=0.15  loss=2993.41  active=4696  feature_norm=38.05\n",
            "Iter 79  time=0.15  loss=2983.20  active=4685  feature_norm=37.99\n",
            "Iter 80  time=0.15  loss=2968.74  active=4610  feature_norm=37.92\n",
            "Iter 81  time=0.15  loss=2955.46  active=4566  feature_norm=37.88\n",
            "Iter 82  time=0.17  loss=2940.06  active=4553  feature_norm=37.83\n",
            "Iter 83  time=0.15  loss=2925.00  active=4484  feature_norm=37.77\n",
            "Iter 84  time=0.15  loss=2916.80  active=4402  feature_norm=37.68\n",
            "Iter 85  time=0.16  loss=2900.78  active=4394  feature_norm=37.68\n",
            "Iter 86  time=0.15  loss=2894.96  active=4376  feature_norm=37.66\n",
            "Iter 87  time=0.15  loss=2888.74  active=4373  feature_norm=37.63\n",
            "Iter 88  time=0.16  loss=2882.28  active=4362  feature_norm=37.61\n",
            "Iter 89  time=0.16  loss=2877.75  active=4317  feature_norm=37.61\n",
            "Iter 90  time=0.16  loss=2871.19  active=4312  feature_norm=37.60\n",
            "Iter 91  time=0.15  loss=2867.78  active=4297  feature_norm=37.59\n",
            "Iter 92  time=0.15  loss=2862.44  active=4284  feature_norm=37.58\n",
            "Iter 93  time=0.15  loss=2858.61  active=4248  feature_norm=37.57\n",
            "Iter 94  time=0.15  loss=2853.31  active=4244  feature_norm=37.59\n",
            "Iter 95  time=0.15  loss=2850.16  active=4231  feature_norm=37.59\n",
            "Iter 96  time=0.15  loss=2847.51  active=4239  feature_norm=37.60\n",
            "Iter 97  time=0.15  loss=2843.47  active=4220  feature_norm=37.62\n",
            "Iter 98  time=0.15  loss=2839.10  active=4196  feature_norm=37.63\n",
            "Iter 99  time=0.16  loss=2835.71  active=4169  feature_norm=37.65\n",
            "Iter 100 time=0.15  loss=2832.46  active=4170  feature_norm=37.67\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 18.813\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 4170 (112428)\n",
            "Number of active attributes: 2858 (107764)\n",
            "Number of active labels: 7 (7)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.004\n",
            "\n",
            "############################## 3 ##############################\n",
            "Converting the DataFrame of the datasetmoro_train_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "309798it [00:15, 19730.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8747/8747 [00:00<00:00, 1485206.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetdegasperi_test_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "27128it [00:01, 19747.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 837/837 [00:00<00:00, 1175303.80it/s]\n",
            "8702it [00:05, 1618.62it/s]\n",
            "825it [00:00, 1788.66it/s]\n",
            "loading training data to CRFsuite: 100%|██████████| 8702/8702 [00:05<00:00, 1689.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 0\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 103940\n",
            "Seconds required: 0.769\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.500000\n",
            "c2: 0.500000\n",
            "num_memories: 6\n",
            "max_iterations: 100\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=0.56  loss=324772.54 active=103272 feature_norm=1.00\n",
            "Iter 2   time=0.28  loss=315035.70 active=63817 feature_norm=0.97\n",
            "Iter 3   time=0.27  loss=52916.79 active=27527 feature_norm=3.87\n",
            "Iter 4   time=2.46  loss=52501.84 active=29646 feature_norm=3.86\n",
            "Iter 5   time=0.56  loss=47513.92 active=29070 feature_norm=3.02\n",
            "Iter 6   time=0.27  loss=47041.57 active=29562 feature_norm=3.52\n",
            "Iter 7   time=0.27  loss=46221.86 active=29604 feature_norm=3.35\n",
            "Iter 8   time=0.28  loss=46136.46 active=30910 feature_norm=3.53\n",
            "Iter 9   time=0.28  loss=45704.57 active=30645 feature_norm=3.43\n",
            "Iter 10  time=0.29  loss=43637.37 active=30184 feature_norm=3.65\n",
            "Iter 11  time=0.28  loss=42403.64 active=29870 feature_norm=3.80\n",
            "Iter 12  time=0.27  loss=41199.82 active=28331 feature_norm=4.98\n",
            "Iter 13  time=0.28  loss=39275.89 active=28401 feature_norm=4.99\n",
            "Iter 14  time=0.27  loss=38432.25 active=24836 feature_norm=5.38\n",
            "Iter 15  time=0.27  loss=36813.36 active=24616 feature_norm=6.08\n",
            "Iter 16  time=0.29  loss=35353.09 active=23611 feature_norm=7.73\n",
            "Iter 17  time=0.29  loss=30332.30 active=23667 feature_norm=10.38\n",
            "Iter 18  time=0.32  loss=28274.04 active=23313 feature_norm=11.68\n",
            "Iter 19  time=0.29  loss=26194.62 active=23674 feature_norm=12.58\n",
            "Iter 20  time=0.29  loss=24305.89 active=23768 feature_norm=14.13\n",
            "Iter 21  time=0.28  loss=21316.33 active=23363 feature_norm=16.21\n",
            "Iter 22  time=0.30  loss=17593.40 active=22716 feature_norm=19.90\n",
            "Iter 23  time=0.82  loss=17153.46 active=21453 feature_norm=20.20\n",
            "Iter 24  time=0.28  loss=15338.65 active=21064 feature_norm=22.21\n",
            "Iter 25  time=0.29  loss=14082.24 active=19520 feature_norm=24.14\n",
            "Iter 26  time=0.28  loss=12788.71 active=18180 feature_norm=25.75\n",
            "Iter 27  time=0.28  loss=11454.77 active=17267 feature_norm=27.11\n",
            "Iter 28  time=0.27  loss=10582.11 active=16346 feature_norm=30.15\n",
            "Iter 29  time=0.84  loss=10032.69 active=15808 feature_norm=30.60\n",
            "Iter 30  time=0.26  loss=9588.47  active=15237 feature_norm=30.96\n",
            "Iter 31  time=0.28  loss=9188.39  active=14794 feature_norm=31.57\n",
            "Iter 32  time=0.29  loss=8486.78  active=13442 feature_norm=33.24\n",
            "Iter 33  time=0.56  loss=8334.21  active=12549 feature_norm=33.77\n",
            "Iter 34  time=0.28  loss=7917.20  active=12235 feature_norm=34.63\n",
            "Iter 35  time=0.28  loss=7344.43  active=11727 feature_norm=35.96\n",
            "Iter 36  time=0.28  loss=6849.18  active=10679 feature_norm=37.11\n",
            "Iter 37  time=0.56  loss=6670.84  active=10539 feature_norm=38.06\n",
            "Iter 38  time=0.28  loss=6151.76  active=10506 feature_norm=38.99\n",
            "Iter 39  time=0.28  loss=5930.76  active=10405 feature_norm=39.90\n",
            "Iter 40  time=0.28  loss=5676.63  active=9979  feature_norm=40.58\n",
            "Iter 41  time=0.28  loss=5311.04  active=9821  feature_norm=41.91\n",
            "Iter 42  time=0.55  loss=5264.61  active=9540  feature_norm=41.67\n",
            "Iter 43  time=0.27  loss=5076.18  active=9010  feature_norm=42.20\n",
            "Iter 44  time=0.28  loss=4969.51  active=8951  feature_norm=42.76\n",
            "Iter 45  time=0.28  loss=4794.43  active=8449  feature_norm=43.95\n",
            "Iter 46  time=0.29  loss=4725.30  active=8120  feature_norm=44.49\n",
            "Iter 47  time=0.28  loss=4666.06  active=8058  feature_norm=44.60\n",
            "Iter 48  time=0.28  loss=4577.48  active=7756  feature_norm=45.11\n",
            "Iter 49  time=0.27  loss=4530.28  active=7633  feature_norm=45.31\n",
            "Iter 50  time=0.27  loss=4444.86  active=7357  feature_norm=45.75\n",
            "Iter 51  time=0.30  loss=4354.76  active=7115  feature_norm=46.19\n",
            "Iter 52  time=0.30  loss=4284.83  active=6999  feature_norm=46.05\n",
            "Iter 53  time=0.28  loss=4190.27  active=6792  feature_norm=46.16\n",
            "Iter 54  time=0.29  loss=4093.06  active=6540  feature_norm=46.01\n",
            "Iter 55  time=0.28  loss=4002.02  active=6311  feature_norm=46.02\n",
            "Iter 56  time=0.30  loss=3937.26  active=6153  feature_norm=45.75\n",
            "Iter 57  time=0.28  loss=3893.13  active=6089  feature_norm=45.63\n",
            "Iter 58  time=0.29  loss=3846.92  active=6062  feature_norm=45.32\n",
            "Iter 59  time=0.28  loss=3792.77  active=5960  feature_norm=45.24\n",
            "Iter 60  time=0.31  loss=3743.71  active=5909  feature_norm=45.03\n",
            "Iter 61  time=0.29  loss=3683.60  active=5754  feature_norm=44.94\n",
            "Iter 62  time=0.29  loss=3644.50  active=5747  feature_norm=44.82\n",
            "Iter 63  time=0.29  loss=3616.79  active=5726  feature_norm=44.81\n",
            "Iter 64  time=0.29  loss=3585.82  active=5655  feature_norm=44.65\n",
            "Iter 65  time=0.27  loss=3549.52  active=5599  feature_norm=44.60\n",
            "Iter 66  time=0.28  loss=3511.79  active=5498  feature_norm=44.49\n",
            "Iter 67  time=0.28  loss=3482.69  active=5464  feature_norm=44.55\n",
            "Iter 68  time=0.29  loss=3460.54  active=5439  feature_norm=44.49\n",
            "Iter 69  time=0.28  loss=3426.94  active=5327  feature_norm=44.44\n",
            "Iter 70  time=0.28  loss=3410.79  active=5320  feature_norm=44.26\n",
            "Iter 71  time=0.27  loss=3385.92  active=5305  feature_norm=44.32\n",
            "Iter 72  time=0.30  loss=3370.79  active=5305  feature_norm=44.22\n",
            "Iter 73  time=0.29  loss=3354.45  active=5275  feature_norm=44.17\n",
            "Iter 74  time=0.29  loss=3339.43  active=5208  feature_norm=44.00\n",
            "Iter 75  time=0.28  loss=3321.75  active=5207  feature_norm=44.00\n",
            "Iter 76  time=0.28  loss=3309.40  active=5195  feature_norm=43.94\n",
            "Iter 77  time=0.28  loss=3289.91  active=5126  feature_norm=43.85\n",
            "Iter 78  time=0.28  loss=3274.24  active=5034  feature_norm=43.74\n",
            "Iter 79  time=0.28  loss=3257.81  active=4996  feature_norm=43.70\n",
            "Iter 80  time=0.29  loss=3246.68  active=4942  feature_norm=43.64\n",
            "Iter 81  time=0.55  loss=3244.93  active=4912  feature_norm=43.57\n",
            "Iter 82  time=0.27  loss=3228.93  active=4946  feature_norm=43.53\n",
            "Iter 83  time=0.28  loss=3223.43  active=4928  feature_norm=43.47\n",
            "Iter 84  time=0.28  loss=3214.07  active=4899  feature_norm=43.41\n",
            "Iter 85  time=0.28  loss=3206.91  active=4863  feature_norm=43.32\n",
            "Iter 86  time=0.28  loss=3198.93  active=4859  feature_norm=43.28\n",
            "Iter 87  time=0.28  loss=3192.43  active=4825  feature_norm=43.20\n",
            "Iter 88  time=0.28  loss=3183.38  active=4793  feature_norm=43.14\n",
            "Iter 89  time=0.28  loss=3172.18  active=4754  feature_norm=43.02\n",
            "Iter 90  time=0.28  loss=3159.00  active=4702  feature_norm=42.95\n",
            "Iter 91  time=0.30  loss=3144.40  active=4648  feature_norm=42.82\n",
            "Iter 92  time=0.29  loss=3132.53  active=4618  feature_norm=42.75\n",
            "Iter 93  time=0.28  loss=3124.88  active=4583  feature_norm=42.63\n",
            "Iter 94  time=0.29  loss=3116.25  active=4585  feature_norm=42.60\n",
            "Iter 95  time=0.29  loss=3110.53  active=4604  feature_norm=42.57\n",
            "Iter 96  time=0.28  loss=3103.10  active=4607  feature_norm=42.55\n",
            "Iter 97  time=0.28  loss=3092.58  active=4572  feature_norm=42.54\n",
            "Iter 98  time=0.27  loss=3086.97  active=4560  feature_norm=42.59\n",
            "Iter 99  time=0.28  loss=3078.57  active=4535  feature_norm=42.57\n",
            "Iter 100 time=0.28  loss=3073.49  active=4528  feature_norm=42.58\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 33.200\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 4528 (103940)\n",
            "Number of active attributes: 2978 (99001)\n",
            "Number of active labels: 7 (7)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.003\n",
            "\n",
            "############################## 4 ##############################\n",
            "Converting the DataFrame of the datasetwikinews_train_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "249077it [00:12, 19692.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7522/7522 [00:00<00:00, 1034581.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetdegasperi_train_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "123504it [00:06, 17748.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3793/3793 [00:00<00:00, 1489048.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetfiction_test_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21506it [00:01, 19872.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 807/807 [00:00<00:00, 1015847.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetmoro_test_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "82806it [00:04, 19143.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2203/2203 [00:00<00:00, 1012497.45it/s]\n",
            "11204it [00:06, 1716.95it/s]\n",
            "2990it [00:01, 1661.11it/s]\n",
            "loading training data to CRFsuite: 100%|██████████| 11204/11204 [00:07<00:00, 1584.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 0\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 232312\n",
            "Seconds required: 1.169\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.500000\n",
            "c2: 0.500000\n",
            "num_memories: 6\n",
            "max_iterations: 100\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=1.12  loss=583958.74 active=225882 feature_norm=0.50\n",
            "Iter 2   time=0.35  loss=537817.33 active=146394 feature_norm=0.45\n",
            "Iter 3   time=1.41  loss=305053.73 active=115266 feature_norm=0.13\n",
            "Iter 4   time=0.72  loss=298854.43 active=135076 feature_norm=0.21\n",
            "Iter 5   time=0.36  loss=281310.20 active=133875 feature_norm=0.18\n",
            "Iter 6   time=0.36  loss=277784.25 active=131925 feature_norm=0.17\n",
            "Iter 7   time=0.37  loss=271442.10 active=144908 feature_norm=0.18\n",
            "Iter 8   time=0.37  loss=270127.69 active=143986 feature_norm=0.19\n",
            "Iter 9   time=0.37  loss=266612.47 active=140902 feature_norm=0.21\n",
            "Iter 10  time=0.38  loss=255698.62 active=136011 feature_norm=0.57\n",
            "Iter 11  time=0.35  loss=207799.19 active=136077 feature_norm=1.00\n",
            "Iter 12  time=0.36  loss=185878.31 active=136977 feature_norm=1.57\n",
            "Iter 13  time=0.73  loss=156755.71 active=137960 feature_norm=1.97\n",
            "Iter 14  time=1.07  loss=155093.98 active=137999 feature_norm=2.31\n",
            "Iter 15  time=0.36  loss=150295.14 active=123431 feature_norm=2.49\n",
            "Iter 16  time=0.38  loss=128757.19 active=125296 feature_norm=2.50\n",
            "Iter 17  time=1.51  loss=119856.12 active=123154 feature_norm=2.54\n",
            "Iter 18  time=0.85  loss=118493.05 active=123558 feature_norm=2.68\n",
            "Iter 19  time=0.90  loss=116903.40 active=121639 feature_norm=2.72\n",
            "Iter 20  time=0.47  loss=115836.71 active=120858 feature_norm=2.90\n",
            "Iter 21  time=0.40  loss=112153.02 active=120871 feature_norm=2.93\n",
            "Iter 22  time=0.39  loss=111886.69 active=121517 feature_norm=2.99\n",
            "Iter 23  time=0.36  loss=111125.31 active=121415 feature_norm=3.01\n",
            "Iter 24  time=0.37  loss=110499.51 active=121680 feature_norm=3.04\n",
            "Iter 25  time=0.38  loss=110468.10 active=121577 feature_norm=3.09\n",
            "Iter 26  time=0.37  loss=109010.30 active=121678 feature_norm=3.16\n",
            "Iter 27  time=0.36  loss=107594.72 active=121625 feature_norm=3.23\n",
            "Iter 28  time=0.37  loss=105371.14 active=121873 feature_norm=3.47\n",
            "Iter 29  time=0.37  loss=101360.79 active=119155 feature_norm=4.01\n",
            "Iter 30  time=0.36  loss=93016.22 active=120718 feature_norm=5.02\n",
            "Iter 31  time=0.38  loss=87804.18 active=120619 feature_norm=5.55\n",
            "Iter 32  time=0.38  loss=84052.89 active=122923 feature_norm=6.12\n",
            "Iter 33  time=0.36  loss=79991.16 active=122268 feature_norm=6.92\n",
            "Iter 34  time=0.37  loss=73810.08 active=120596 feature_norm=8.34\n",
            "Iter 35  time=0.37  loss=68182.22 active=107783 feature_norm=10.29\n",
            "Iter 36  time=0.37  loss=64218.64 active=105513 feature_norm=11.84\n",
            "Iter 37  time=0.39  loss=57731.34 active=100423 feature_norm=15.30\n",
            "Iter 38  time=1.51  loss=57265.61 active=98579 feature_norm=15.62\n",
            "Iter 39  time=0.37  loss=53011.37 active=97748 feature_norm=17.77\n",
            "Iter 40  time=0.37  loss=49535.81 active=94795 feature_norm=20.02\n",
            "Iter 41  time=0.38  loss=45939.63 active=88553 feature_norm=23.16\n",
            "Iter 42  time=0.37  loss=43851.75 active=84137 feature_norm=25.85\n",
            "Iter 43  time=0.38  loss=42096.87 active=83026 feature_norm=27.10\n",
            "Iter 44  time=0.38  loss=40519.79 active=81940 feature_norm=28.63\n",
            "Iter 45  time=0.37  loss=38169.65 active=78302 feature_norm=30.93\n",
            "Iter 46  time=0.38  loss=36623.88 active=73872 feature_norm=32.87\n",
            "Iter 47  time=0.38  loss=34991.27 active=72180 feature_norm=35.80\n",
            "Iter 48  time=0.39  loss=33577.81 active=71063 feature_norm=37.58\n",
            "Iter 49  time=0.36  loss=32236.72 active=69352 feature_norm=39.13\n",
            "Iter 50  time=0.77  loss=31439.72 active=63821 feature_norm=39.94\n",
            "Iter 51  time=0.37  loss=30279.54 active=62677 feature_norm=41.48\n",
            "Iter 52  time=0.36  loss=30010.95 active=63429 feature_norm=41.51\n",
            "Iter 53  time=0.37  loss=29473.77 active=62678 feature_norm=42.02\n",
            "Iter 54  time=0.36  loss=28077.47 active=59474 feature_norm=45.36\n",
            "Iter 55  time=1.10  loss=27915.69 active=58619 feature_norm=46.06\n",
            "Iter 56  time=0.37  loss=27292.24 active=56419 feature_norm=47.14\n",
            "Iter 57  time=0.38  loss=26538.35 active=54957 feature_norm=50.02\n",
            "Iter 58  time=0.37  loss=25880.47 active=54096 feature_norm=51.97\n",
            "Iter 59  time=0.40  loss=25085.08 active=52606 feature_norm=54.79\n",
            "Iter 60  time=0.39  loss=24904.94 active=50316 feature_norm=58.18\n",
            "Iter 61  time=0.37  loss=24066.99 active=50850 feature_norm=58.58\n",
            "Iter 62  time=0.37  loss=23754.94 active=50544 feature_norm=59.34\n",
            "Iter 63  time=0.36  loss=23286.21 active=49712 feature_norm=61.11\n",
            "Iter 64  time=0.37  loss=22712.21 active=48778 feature_norm=64.67\n",
            "Iter 65  time=0.36  loss=22424.97 active=48789 feature_norm=65.27\n",
            "Iter 66  time=0.36  loss=22280.18 active=48662 feature_norm=65.72\n",
            "Iter 67  time=0.36  loss=21777.44 active=47187 feature_norm=67.44\n",
            "Iter 68  time=0.38  loss=21622.65 active=47019 feature_norm=68.08\n",
            "Iter 69  time=0.36  loss=21428.11 active=46565 feature_norm=69.02\n",
            "Iter 70  time=0.36  loss=21198.97 active=45206 feature_norm=71.90\n",
            "Iter 71  time=0.37  loss=21135.99 active=43639 feature_norm=72.96\n",
            "Iter 72  time=0.40  loss=20981.72 active=44000 feature_norm=72.90\n",
            "Iter 73  time=0.38  loss=20943.53 active=43843 feature_norm=73.00\n",
            "Iter 74  time=0.35  loss=20859.78 active=43206 feature_norm=73.27\n",
            "Iter 75  time=0.39  loss=20728.36 active=41709 feature_norm=73.48\n",
            "Iter 76  time=0.36  loss=20695.90 active=41695 feature_norm=73.31\n",
            "Iter 77  time=0.36  loss=20627.37 active=41786 feature_norm=73.35\n",
            "Iter 78  time=0.36  loss=20586.86 active=41648 feature_norm=73.27\n",
            "Iter 79  time=0.37  loss=20481.10 active=41153 feature_norm=72.84\n",
            "Iter 80  time=0.74  loss=20384.56 active=40276 feature_norm=72.30\n",
            "Iter 81  time=0.36  loss=20253.36 active=40111 feature_norm=72.13\n",
            "Iter 82  time=0.37  loss=20168.04 active=39741 feature_norm=72.07\n",
            "Iter 83  time=0.36  loss=20041.98 active=38255 feature_norm=72.33\n",
            "Iter 84  time=0.36  loss=19917.75 active=38210 feature_norm=72.37\n",
            "Iter 85  time=0.37  loss=19862.64 active=38120 feature_norm=72.42\n",
            "Iter 86  time=0.38  loss=19754.84 active=37127 feature_norm=72.58\n",
            "Iter 87  time=0.38  loss=19635.05 active=36521 feature_norm=72.80\n",
            "Iter 88  time=0.37  loss=19541.64 active=36565 feature_norm=72.95\n",
            "Iter 89  time=0.37  loss=19459.31 active=36262 feature_norm=72.95\n",
            "Iter 90  time=0.37  loss=19301.30 active=35288 feature_norm=73.01\n",
            "Iter 91  time=0.36  loss=19241.00 active=35311 feature_norm=72.89\n",
            "Iter 92  time=0.35  loss=19198.97 active=35500 feature_norm=72.87\n",
            "Iter 93  time=0.37  loss=19100.31 active=35287 feature_norm=72.74\n",
            "Iter 94  time=0.36  loss=19026.12 active=35012 feature_norm=72.62\n",
            "Iter 95  time=0.37  loss=18962.24 active=34483 feature_norm=72.47\n",
            "Iter 96  time=0.36  loss=18893.96 active=34482 feature_norm=72.45\n",
            "Iter 97  time=0.38  loss=18853.35 active=34547 feature_norm=72.41\n",
            "Iter 98  time=0.38  loss=18779.13 active=34283 feature_norm=72.38\n",
            "Iter 99  time=0.41  loss=18699.78 active=33972 feature_norm=72.27\n",
            "Iter 100 time=0.38  loss=18646.16 active=33643 feature_norm=72.18\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 45.139\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 33643 (232312)\n",
            "Number of active attributes: 25163 (205978)\n",
            "Number of active labels: 7 (7)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.021\n",
            "\n",
            "############################## 5 ##############################\n",
            "Converting the DataFrame of the datasetwikinews_train_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "249077it [00:12, 19463.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7522/7522 [00:00<00:00, 1657536.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetfiction_train_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "170942it [00:08, 19011.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7479/7479 [00:00<00:00, 1344010.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetfiction_test_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21506it [00:01, 18921.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 807/807 [00:00<00:00, 1132041.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting the DataFrame of the datasetwikinews_test_BIO.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "59220it [00:03, 19407.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing short sentences from the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1804/1804 [00:00<00:00, 1185232.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## NER Transformers\n",
        "\n",
        "A transformer is a deep learning model that is different from the classical models since it adopts **self-attention.** It is used primarly in the fields of NLP and computer vision.\n",
        "In general there are two big families of transformers:\n",
        "- Transformer encoder layers, like BERT.\n",
        "- Transformer decoder layers, like GPT.\n",
        "\n",
        "Bert was pre-trained for two tasks:\n",
        "- Language modeling;\n",
        "- Next sentence prediction\n",
        "\n",
        "As a result of this training process, BERT learns latent representations of words and sentences in context. After pre-training, BERT can be **fine-tuned** with fewer resources on smaller datasets to optimize its performance on specific tasks such as NLP tasks (language inference, text classification) and sequence-to-sequence based language generation tasks (question-answering, conversational response generation).\n",
        "\n",
        "In our case we will fine-tune BERT for Token Classification, that takes as input a sequence of tokens and the respective entity tag.\n",
        "\n",
        "Since the dataset is already tokenized and cleaned by the authors we won't apply any type of pre-processing.\n",
        "\n",
        "We will use two different models pre-trained for the italian language:\n",
        "- bert italian xxl cased\n",
        "- bert base multilingual.\n",
        "\n",
        "For each of them we performed cross-validation to choose the most important hyperparameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "rvMVjgT4flfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createDataset(train, test):\n",
        "\n",
        "  '''\n",
        "  Takes two dataframes and it creates an Hugging Face Dictionary of Datasets\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  train: DataFrame\n",
        "    Train DataFrame\n",
        "  test: DataFrame\n",
        "    Test DataFrame\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  dataset_hf: DatasetDict\n",
        "    Dictionary of Hugging Face Datasets\n",
        "  '''\n",
        "  \n",
        "  train_dataset = Dataset.from_pandas(train)\n",
        "  test_dataset = Dataset.from_pandas(test)\n",
        "  dataset_hf = DatasetDict()\n",
        "  \n",
        "  dataset_hf['train'] = train_dataset\n",
        "  dataset_hf['test'] = test_dataset\n",
        "\n",
        "  return dataset_hf"
      ],
      "metadata": {
        "id": "wpdjHxmxpwv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code we create all the data structures that we will need to \n",
        "fine-tune our model.\n",
        "We decided to use as train dataset the union of all the datasets given.\n",
        "Then, we will predict and evaluate the performances of each model over all the test datasets."
      ],
      "metadata": {
        "id": "QMEFpcr5XkKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset composed of all the train datasets\n",
        "datasets_merged = pd.concat(datasets_train_dict_BIO.values(), ignore_index=True)\n",
        "\n",
        "# Create of a dictionary that maps all the entity inside the dataset with an incremental id\n",
        "entity_names = pd.unique(datasets_merged['Entity'])\n",
        "entity_names_dict = {}\n",
        "for i, label in enumerate(entity_names):\n",
        "  entity_names_dict[label] = i\n",
        "\n",
        "id2label = {}\n",
        "for i, label in enumerate(entity_names):\n",
        "  id2label[i] = label\n",
        "\n",
        "# Creation of all the sentence and the respected labels for the entire dataset\n",
        "sentences, labels, keys = get_sentences_list_from_df(datasets_merged)\n",
        "train_dataset = pd.DataFrame(columns=['Tokens', 'Labels'])\n",
        "\n",
        "# Creation of a DataFrame with all the sentences\n",
        "for i in range(len(sentences)):\n",
        "  train_dataset.at[i, 'Tokens'] = sentences[i]\n",
        "  train_dataset.at[i, 'Labels'] = labels[i]"
      ],
      "metadata": {
        "id": "kb5P1UfzhXux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Controll of the possibility to use cuda\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Download bert models from hugging face\n",
        "model_name_xxl = 'dbmdz/bert-base-italian-xxl-cased'\n",
        "model_name_multi = 'bert-base-multilingual-cased'\n",
        "\n",
        "model_xxl = AutoModelForTokenClassification.from_pretrained(model_name_xxl, num_labels=len(entity_names), label2id=entity_names_dict, id2label=id2label).to(device)\n",
        "model_multi = AutoModelForTokenClassification.from_pretrained(model_name_multi, num_labels=len(entity_names), label2id=entity_names_dict, id2label=id2label).to(device)"
      ],
      "metadata": {
        "id": "s4iMtx2ci2Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "\n",
        "    '''\n",
        "    Takes a batch of examples. Tokenize the examples and since the bert is performing a sub-tokenization we have to allign the original labels to the actual sub-tokens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    examples: dict\n",
        "      Dictionary having as values for the key Tokens a list of list of tokenized senteces.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tokenized_inputs: dict\n",
        "      dictionary that containt the input_ids created by the bert tokenizer and the respected labels for each token alligned as the initial ones.\n",
        "  \n",
        "    '''\n",
        "    # Tokenization of the sentences\n",
        "    label_all_tokens = True\n",
        "    tokenized_inputs = tokenizer(list(examples[\"Tokens\"]), truncation=True, is_split_into_words=True)\n",
        "\n",
        "    # Alignment of the labels with the original tokens\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['Labels']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif label[word_idx] == '0':\n",
        "                label_ids.append(0)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(entity_names_dict[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(entity_names_dict[label[word_idx]] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "        \n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "C4kQLn48jh1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "\n",
        "    '''\n",
        "    It calculates the metrics of a batch of predictions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    p: tuple\n",
        "      Tuple composed of the predictions by the transformer and the respected original labels.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    entity_metrics: dict\n",
        "      dictionary of dictionaries that contains for each entity the respected computed metrics\n",
        "\n",
        "    '''\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    entity_metrics = {}\n",
        "    for entity_name in entity_names:\n",
        "\n",
        "        # Take the predictions and the labels of the specific entity (when the original one was that entity)\n",
        "        true_predictions = [[entity_names[p] for (p, l) in zip(prediction, label) if l != -100 and entity_names[l] == entity_name] for prediction, label in zip(predictions, labels)]\n",
        "        true_labels = [[entity_names[l] for (p, l) in zip(prediction, label) if l != -100 and entity_names[l] == entity_name] for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "        # Compute the metrics for that specific entity\n",
        "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "        entity_metrics[entity_name] = {\n",
        "            \"precision\": results[\"overall_precision\"],\n",
        "            \"recall\": results[\"overall_recall\"],\n",
        "            \"f1\": results[\"overall_f1\"],\n",
        "            \"accuracy\": results[\"overall_accuracy\"],\n",
        "        }\n",
        "\n",
        "    return entity_metrics"
      ],
      "metadata": {
        "id": "V4eIA2Ktsvu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mean_metrics_cv(results):\n",
        "\n",
        "  '''\n",
        "  It calculates the metrics of a cross-validation.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  results: list\n",
        "    list that contains all the metrics calculated for each entity every round of the cross-validation.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  metrics: dict\n",
        "    dictionary of dictionaries that contains for each entity the mean of the metrics.\n",
        "\n",
        "  '''\n",
        "\n",
        "  metrics = {}\n",
        "  for entity_name in entity_names:\n",
        "    metrics[entity_name] = {\n",
        "            \"precision\": sum([scores[f'eval_{entity_name}']['precision'] for scores in results]) / len(results),\n",
        "            \"recall\":  sum([scores[f'eval_{entity_name}']['recall'] for scores in results]) / len(results),\n",
        "            \"f1\":  sum([scores[f'eval_{entity_name}']['f1'] for scores in results]) / len(results),\n",
        "            \"accuracy\":  sum([scores[f'eval_{entity_name}']['accuracy'] for scores in results]) / len(results)\n",
        "        }\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "kqSauVJuygP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Validation\n",
        "Here we did a cross-validation to find the best hyperparameters for our model.\n",
        "Calculating the performances of each round and then the mean of all the rounds for that specific pair of hyperparameters."
      ],
      "metadata": {
        "id": "lpu2JiOvXznM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [2e-5, 3e-5]\n",
        "epochs = [2,3,4]\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_xxl)\n",
        "\n",
        "results = []\n",
        "# Perform of cross-validation\n",
        "for lr in learning_rates:\n",
        "  for epoch in epochs:\n",
        "    results_cv = []\n",
        "    for i in range(3):    # Cross-validation made of three rounds\n",
        "      train, val = train_test_split(train_dataset, test_size=0.2, shuffle=True)\n",
        "      dataset_hf = createDataset(train, val)\n",
        "      tokenized_datasets = dataset_hf.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "      # Definition of the Transformer's arguments\n",
        "      args = TrainingArguments(output_dir='ner',\n",
        "                               evaluation_strategy = \"no\",\n",
        "                               learning_rate=lr,\n",
        "                               per_device_train_batch_size=32,\n",
        "                               per_device_eval_batch_size=32,\n",
        "                               num_train_epochs=epoch,\n",
        "                               weight_decay=0.01,\n",
        "                               push_to_hub=False,\n",
        "                               disable_tqdm=False\n",
        "                              )\n",
        "\n",
        "      # Creation of the trainer\n",
        "      trainer = Trainer(\n",
        "          model_xxl,\n",
        "          args,\n",
        "          train_dataset=tokenized_datasets['train'],\n",
        "          eval_dataset = tokenized_datasets['test'],\n",
        "          data_collator=data_collator,\n",
        "          compute_metrics=compute_metrics,\n",
        "          tokenizer=tokenizer,\n",
        "      )\n",
        "      trainer.train()\n",
        "      results_cv.append(trainer.evaluate())             # Add the matrics for that round to the results of the actual cross-validation\n",
        "    results.append(compute_mean_metrics_cv(results_cv)) # Calculate the metrics' mean of the cross-validation"
      ],
      "metadata": {
        "id": "alQ8OBv7mumU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the final model\n",
        "Now, that we found the best hyperparameter, we can train the model over the entire training set.\n",
        "In this case, first of all, we train the italian model."
      ],
      "metadata": {
        "id": "es9ivtESX8fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_hf = Dataset.from_pandas(train_dataset)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_xxl)\n",
        "tokenized_dataset = dataset_hf.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "args = TrainingArguments(output_dir='ner',\n",
        "                          evaluation_strategy = \"no\",\n",
        "                          learning_rate=2e-5,\n",
        "                          per_device_train_batch_size=32,\n",
        "                          per_device_eval_batch_size=32,\n",
        "                          num_train_epochs=4,\n",
        "                          weight_decay=0.01,\n",
        "                          push_to_hub=False,\n",
        "                          disable_tqdm=False\n",
        "                        )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model_xxl,\n",
        "    args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "lv1TjLp_AMs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We evaluate the model over all the datasets."
      ],
      "metadata": {
        "id": "TAVOgYPtYAoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_test = []\n",
        "for test in datasets_test_dict_BIO.values():\n",
        "  sentences, labels, keys = get_sentences_list_from_df(test)\n",
        "  test_dataset = pd.DataFrame(columns=['Tokens', 'Labels'])\n",
        "  for i in range(len(sentences)):\n",
        "    test_dataset.at[i, 'Tokens'] = sentences[i]\n",
        "    test_dataset.at[i, 'Labels'] = labels[i]\n",
        "    \n",
        "  test_dataset = Dataset.from_pandas(test_dataset)\n",
        "  test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "  results_test.append(trainer.evaluate(test_dataset))"
      ],
      "metadata": {
        "id": "MJFafjESGd4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_test_merged = pd.concat(datasets_test_dict_BIO.values(), ignore_index=True)\n",
        "sentences, labels, keys = get_sentences_list_from_df(datasets_test_merged)\n",
        "test_dataset = pd.DataFrame(columns=['Tokens', 'Labels'])\n",
        "for i in range(len(sentences)):\n",
        "  test_dataset.at[i, 'Tokens'] = sentences[i]\n",
        "  test_dataset.at[i, 'Labels'] = labels[i]\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "Y9zAa8xeGpsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We repeat the same for the multilingual model."
      ],
      "metadata": {
        "id": "CECQUBYoYJhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_hf = Dataset.from_pandas(train_dataset)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_multi)\n",
        "tokenized_dataset = dataset_hf.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "args = TrainingArguments(output_dir='ner',\n",
        "                          evaluation_strategy = \"no\",\n",
        "                          learning_rate=2e-5,\n",
        "                          per_device_train_batch_size=16,\n",
        "                          per_device_eval_batch_size=16,\n",
        "                          num_train_epochs=4,\n",
        "                          weight_decay=0.01,\n",
        "                          push_to_hub=False,\n",
        "                          disable_tqdm=False\n",
        "                        )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model_multi,\n",
        "    args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "TcamNzjVYMol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_test = []\n",
        "for test in datasets_test_dict_BIO.values():\n",
        "  sentences, labels, keys = get_sentences_list_from_df(test)\n",
        "  test_dataset = pd.DataFrame(columns=['Tokens', 'Labels'])\n",
        "  for i in range(len(sentences)):\n",
        "    test_dataset.at[i, 'Tokens'] = sentences[i]\n",
        "    test_dataset.at[i, 'Labels'] = labels[i]\n",
        "    \n",
        "  test_dataset = Dataset.from_pandas(test_dataset)\n",
        "  test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "  results_test.append(trainer.evaluate(test_dataset))"
      ],
      "metadata": {
        "id": "3Gmsk5BEYOxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_test_merged = pd.concat(datasets_test_dict_BIO.values(), ignore_index=True)\n",
        "sentences, labels, keys = get_sentences_list_from_df(datasets_test_merged)\n",
        "test_dataset = pd.DataFrame(columns=['Tokens', 'Labels'])\n",
        "for i in range(len(sentences)):\n",
        "  test_dataset.at[i, 'Tokens'] = sentences[i]\n",
        "  test_dataset.at[i, 'Labels'] = labels[i]\n",
        "test_dataset = Dataset.from_pandas(test_dataset)\n",
        "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "trainer.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "mCOsAC0MYQ9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoDrRGFIgFpZ"
      },
      "source": [
        "## CODICE ELIA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUVSRpgmEVNV"
      },
      "source": [
        "# KIND DATASET\n",
        "\n",
        "## Brief Description\n",
        "KIND (Kessler Italian Named-entities Dataset) is a dataset released in 2022 by researchers from Fondazione Bruno Kessler and the University of Trento. It contains 1 million tokens, of which 600K name-entities are manually annotated. The entities belong to 3 classes (people, location, organization). The texts come from various sources of the Italian language, such as news articles, literature, and political speeches, making it a multi-domain dataset. \n",
        "The following table shows the dataset composition:\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\">Dataset</th>\n",
        "      <th rowspan=\"2\">Documents</th>\n",
        "      <th rowspan=\"2\">Tokens</th>\n",
        "      <th colspan=\"4\">Train</th>\n",
        "      <th colspan=\"4\">Test</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Total</th>\n",
        "      <th>PER</th>\n",
        "      <th>ORG</th>\n",
        "      <th>LOC</th>\n",
        "      <th>Total</th>\n",
        "      <th>PER</th>\n",
        "      <th>ORG</th>\n",
        "      <th>LOC</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>Wikinews</td>\n",
        "      <td>1,000</td>\n",
        "      <td>308,622</td>\n",
        "      <td>247,528</td>\n",
        "      <td>8,928</td>\n",
        "      <td>7,593</td>\n",
        "      <td>6,862</td>\n",
        "      <td>61,094</td>\n",
        "      <td>1,802</td>\n",
        "      <td>1,823</td>\n",
        "      <td>1,711</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Fiction</td>\n",
        "      <td>86</td>\n",
        "      <td>192,448</td>\n",
        "      <td>170,942</td>\n",
        "      <td>3,439</td>\n",
        "      <td>182</td>\n",
        "      <td>733</td>\n",
        "      <td>21,506</td>\n",
        "      <td>636</td>\n",
        "      <td>284</td>\n",
        "      <td>463</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Aldo Moro</td>\n",
        "      <td>250</td>\n",
        "      <td>392,604</td>\n",
        "      <td>309,798</td>\n",
        "      <td>1,459</td>\n",
        "      <td>4,842</td>\n",
        "      <td>2,024</td>\n",
        "      <td>82,806</td>\n",
        "      <td>282</td>\n",
        "      <td>934</td>\n",
        "      <td>807</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Alcide De Gasperi</td>\n",
        "      <td>158</td>\n",
        "      <td>150,632</td>\n",
        "      <td>117,997</td>\n",
        "      <td>1,129</td>\n",
        "      <td>2,396</td>\n",
        "      <td>1,046</td>\n",
        "      <td>32,635</td>\n",
        "      <td>253</td>\n",
        "      <td>533</td>\n",
        "      <td>274</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><strong>Total</strong></td>\n",
        "      <td><strong>1494</strong></td>\n",
        "      <td><strong>1,044,306</strong></td>\n",
        "      <td><strong>846,265</strong></td>\n",
        "      <td><strong>14,955</strong></td>\n",
        "      <td><strong>15,013</strong></td>\n",
        "      <td><strong>10,665</strong></td>\n",
        "      <td><strong>198,041</strong></td>\n",
        "      <td><strong>2,973</strong></td>\n",
        "      <td><strong>3,574</strong></td>\n",
        "      <td><strong>3,255</strong></td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n",
        "\n",
        "##Annotation Tagging scheme\n",
        "The tokens of all datasets, except for Aldo Moro, have been manually labeled using the IOB (Inside-Outside-Beginning) convention: each entity is labeled as begin-of-entity (B-[ent]) or continuation-of-entity (I-[ent]). The annotations of the Aldo Moro dataset, instead, were carried out with a mixed process that used both manual and automatic annotations (subsequently checked by hand); due to some differences in the convention for annotation, this dataset does not contain information for composite entities (beginning, continuation). For more details, please refer to the paper related with the dataset release: https://arxiv.org/abs/2112.15099\n",
        "\n",
        "An example of the annotations is reported here: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "durfizxkrnhW"
      },
      "source": [
        "# IOB annotation (from ADG_dev.tsv)\n",
        "Nel\tO\n",
        "nostro\tO\n",
        "Trentino\tB-LOC\n",
        "attraversiamo\tO\n",
        "un\tO\n",
        "momento\tO\n",
        "storico\tO\n",
        "importante\tO\n",
        ".\tO\n",
        "\n",
        "# non-IOB annotation (from moro_test.tsv)\n",
        "Dal\tO\n",
        "Consiglio\tORG\n",
        "nazionale\tORG\n",
        "del\tO\n",
        "‘\tO\n",
        "75\tO\n",
        "la\tO\n",
        "grande\tO\n",
        "stampa\tO\n",
        "parla\tO\n",
        "di\tO\n",
        "due\tO\n",
        "anime\tO\n",
        "contrapposte\tO\n",
        "del\tO\n",
        "partito\tO\n",
        ".\tO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9ejTFLxdf_z"
      },
      "source": [
        "CODICE PER CHARTS. RIMUOVO LE MBRERIE IN SEGUITO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUxTIXvXdgoV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import pi\n",
        "from matplotlib import rc\n",
        "\n",
        "\n",
        "\n",
        "BIO_PATH = '../datasets/BIO_tag_NER_notation/'\n",
        "nonBIO_PATH = '../datasets/Inside_outside_NER_notation/'\n",
        "\n",
        "\n",
        "SPIDER_ROW_N = 2\n",
        "SPIDER_COL_N = 2\n",
        "BAR_ROW_N = 1 \n",
        "BAR_COL_N = 2\n",
        "\n",
        "def to_lowerCase(df):\n",
        "    return pd.DataFrame({'Token': df['Token'].str.lower(), 'Entity': df['Entity']})\n",
        "\n",
        "def add_column_names(df):\n",
        "    return  df.rename(columns={0: 'Token', 1: 'Entity'})\n",
        "\n",
        "def spider_plot(df, group, title, subplot_idx):\n",
        "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "    categories=list(df)[:]\n",
        "    N = len(categories)\n",
        "    \n",
        "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
        "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "    angles += angles[:1]\n",
        "    \n",
        "    # Initialise the spider plot\n",
        "    ax = plt.subplot(SPIDER_ROW_N, SPIDER_COL_N, subplot_idx, polar=True)\n",
        "    \n",
        "    # first axis to be on top:\n",
        "    ax.set_theta_offset(pi / 2)\n",
        "    ax.set_theta_direction(-1)\n",
        "    \n",
        "    # Draw one axe per variable + add labels\n",
        "    plt.xticks(angles[:-1], categories)\n",
        "    \n",
        "    # Draw ylabels\n",
        "    #ax.set_yscale('log')\n",
        "    ax.set_rlabel_position(0)\n",
        "    min = df.min().min()\n",
        "    max = df.max().max()\n",
        "    plt.ylim(min -(max-min)/10, max + (max-min)/10)\n",
        " \n",
        "    # Plot each individual = each line of the data\n",
        "    # I don't make a loop, because plotting more than 3 groups makes the chart unreadable\n",
        "    \n",
        "    for i in range(len(group)):\n",
        "        values=df.loc[i].values.flatten().tolist()\n",
        "        values += values[:1]\n",
        "        ax.plot(angles, values, linewidth=1, linestyle='solid', label=group[i])\n",
        "        ax.fill(angles, values, 'b', alpha=0.1)\n",
        "\n",
        "    \n",
        "    # Add legend\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "    plt.title(title)\n",
        "\n",
        "    # Show the graph\n",
        "    #plt.show()\n",
        "\n",
        "############################################################### reading datasets ###############################################################\n",
        "\n",
        "ds = {'ds_mr'           : pd.read_csv(nonBIO_PATH + 'moro_train.tsv', sep='\\t', header=None),\n",
        "      'ds_mr_test'      : pd.read_csv(nonBIO_PATH + 'moro_test.tsv', sep='\\t', header=None),\n",
        "      \n",
        "      'ds_dg_IOB'       : pd.read_csv(BIO_PATH + 'degasperi_train_BIO.tsv', sep='\\t', header=None),\n",
        "      'ds_fc_IOB'       : pd.read_csv(BIO_PATH + 'fiction_train_BIO.tsv', sep='\\t', header=None),\n",
        "      'ds_wn_IOB'       : pd.read_csv(BIO_PATH + 'wikinews_train_BIO.tsv', sep='\\t', header=None),\n",
        "      'ds_dg_IOB_test'  : pd.read_csv(BIO_PATH + 'degasperi_test_BIO.tsv', sep='\\t', header=None),\n",
        "      'ds_fc_IOB_test'  : pd.read_csv(BIO_PATH + 'fiction_test_BIO.tsv', sep='\\t', header=None),\n",
        "      'ds_wn_IOB_test'  : pd.read_csv(BIO_PATH + 'wikinews_test_BIO.tsv', sep='\\t', header=None)\n",
        "}\n",
        "\n",
        "############################################################### calculating stats ###############################################################\n",
        "stats = {}\n",
        "\n",
        "for i in ds.keys():     \n",
        "    ds[i] = add_column_names(ds[i])\n",
        "    ds[i] = to_lowerCase(ds[i])\n",
        "\n",
        "    stats[i] = {\n",
        "        'doc_len' : ds[i]['Token'].count(),\n",
        "        'voc_size' : ds[i]['Token'].nunique(),\n",
        "        'n_punct': sum(1 for k in ds[i]['Token'] if all(char in string.punctuation for char in k))\n",
        "    }\n",
        "\n",
        "    if('IOB' in str(i)):\n",
        "        \n",
        "        stats[i]['n_I-PER'] = sum(1 for k in ds[i]['Entity'] if k == 'I-PER') \n",
        "        stats[i]['n_I-ORG'] = sum(1 for k in ds[i]['Entity'] if k == 'I-ORG')\n",
        "        stats[i]['n_I-LOC'] = sum(1 for k in ds[i]['Entity'] if k == 'I-LOC')\n",
        "\n",
        "        stats[i]['n_B-PER'] = sum(1 for k in ds[i]['Entity'] if k == 'B-PER') \n",
        "        stats[i]['n_B-ORG'] = sum(1 for k in ds[i]['Entity'] if k == 'B-ORG')\n",
        "        stats[i]['n_B-LOC'] = sum(1 for k in ds[i]['Entity'] if k == 'B-LOC')\n",
        "\n",
        "        stats[i]['n_PER'] = stats[i]['n_I-PER'] + stats[i]['n_B-PER']\n",
        "        stats[i]['n_ORG'] = stats[i]['n_I-ORG'] + stats[i]['n_B-ORG']\n",
        "        stats[i]['n_LOC'] = stats[i]['n_I-LOC'] + stats[i]['n_B-LOC']\n",
        "        \n",
        "    else:\n",
        "        stats[i]['n_PER'] = sum(1 for k in ds[i]['Entity'] if k == 'PER') \n",
        "        stats[i]['n_ORG'] = sum(1 for k in ds[i]['Entity'] if k == 'ORG')\n",
        "        stats[i]['n_LOC'] = sum(1 for k in ds[i]['Entity'] if k == 'LOC')\n",
        "\n",
        "    stats[i]['n_O'] = sum(1 for k in ds[i]['Entity'] if k == 'O')\n",
        "        \n",
        "\n",
        "avg_doc_len = sum(stats[i]['doc_len'] for i in stats.keys()) / len(stats.keys())\n",
        "avg_voc_size = sum(stats[i]['voc_size'] for i in stats.keys()) / len(stats.keys())\n",
        "\n",
        "############################################################### preparing data for plotting ###############################################################\n",
        " \n",
        "# Values of each group\n",
        "iper = [stats[i]['n_I-PER'] for i in stats.keys() if 'IOB' in str(i) and 'test' not in str(i)]\n",
        "iorg = [stats[i]['n_I-ORG'] for i in stats.keys() if 'IOB' in str(i) and 'test' not in str(i)]\n",
        "iloc = [stats[i]['n_I-LOC'] for i in stats.keys() if 'IOB' in str(i) and 'test' not in str(i)]\n",
        "\n",
        "bper = [stats[i]['n_B-PER'] for i in stats.keys() if 'IOB' in str(i) and 'test' not in str(i)]\n",
        "borg = [stats[i]['n_B-ORG'] for i in stats.keys() if 'IOB' in str(i) and 'test' not in str(i)]\n",
        "bloc = [stats[i]['n_B-LOC'] for i in stats.keys() if 'IOB' in str(i) and 'test' not in str(i)]\n",
        "\n",
        "iob_punct = [stats[i]['n_punct'] for i in stats.keys() if 'IOB' in str(i) and 'test' not in str(i)]\n",
        "iob_o = [stats[i]['n_O'] for i in stats.keys() if 'IOB' in str(i) and 'test' not in str(i)]\n",
        "iob_o = [iob_o[i] - iob_punct[i] for i in range(len(iob_o))]\n",
        "\n",
        "iper_test = [stats[i]['n_I-PER'] for i in stats.keys() if 'IOB' in str(i) and 'test' in str(i)]\n",
        "iorg_test = [stats[i]['n_I-ORG'] for i in stats.keys() if 'IOB' in str(i) and 'test' in str(i)]\n",
        "iloc_test = [stats[i]['n_I-LOC'] for i in stats.keys() if 'IOB' in str(i) and 'test' in str(i)]\n",
        "\n",
        "bper_test = [stats[i]['n_B-PER'] for i in stats.keys() if 'IOB' in str(i) and 'test' in str(i)]\n",
        "borg_test = [stats[i]['n_B-ORG'] for i in stats.keys() if 'IOB' in str(i) and 'test' in str(i)]\n",
        "bloc_test = [stats[i]['n_B-LOC'] for i in stats.keys() if 'IOB' in str(i) and 'test' in str(i)]\n",
        "\n",
        "iob_punct_test = [stats[i]['n_punct'] for i in stats.keys() if 'IOB' in str(i) and 'test' in str(i)]\n",
        "iob_o_test = [stats[i]['n_O'] for i in stats.keys() if 'IOB' in str(i) and 'test' in str(i)]\n",
        "iob_o_test = [iob_o_test[i] - iob_punct_test[i] for i in range(len(iob_o_test))]\n",
        "\n",
        "iob_voc_size = [stats[i]['voc_size'] for i in stats.keys() if 'IOB' in str(i)]\n",
        "\n",
        "per = [stats[i]['n_PER'] for i in stats.keys() if 'test' not in str(i)]\n",
        "org = [stats[i]['n_ORG'] for i in stats.keys() if 'test' not in str(i)]\n",
        "loc = [stats[i]['n_LOC'] for i in stats.keys() if 'test' not in str(i)]\n",
        "\n",
        "per_test = [stats[i]['n_PER'] for i in stats.keys() if 'test' in str(i)]\n",
        "org_test = [stats[i]['n_ORG'] for i in stats.keys() if 'test' in str(i)]\n",
        "loc_test = [stats[i]['n_LOC'] for i in stats.keys() if 'test' in str(i)]\n",
        "\n",
        "voc_size = [stats[i]['voc_size'] for i in stats.keys() if 'test' not in str(i)]\n",
        "voc_size_test = [stats[i]['voc_size'] for i in stats.keys() if 'test' in str(i)]\n",
        "\n",
        "doc_len = [stats[i]['doc_len'] for i in stats.keys() if 'test' not in str(i)]\n",
        "doc_len_test = [stats[i]['doc_len'] for i in stats.keys() if 'test' in str(i)]\n",
        "\n",
        "n_punct = [stats[i]['n_punct'] for i in stats.keys() if 'test' not in str(i)]\n",
        "n_punct_test = [stats[i]['n_punct'] for i in stats.keys() if 'test' in str(i)]\n",
        "\n",
        "o = [stats[i]['n_O'] for i in stats.keys() if 'test' not in str(i)]\n",
        "punct = [stats[i]['n_punct'] for i in stats.keys() if 'test' not in str(i)]\n",
        "\n",
        "\n",
        "o_test = [stats[i]['n_O'] for i in stats.keys() if 'test' in str(i)]\n",
        "punct_test = [stats[i]['n_punct'] for i in stats.keys() if 'test' in str(i)]\n",
        "\n",
        "############################################################### spider plots ###############################################################\n",
        "\n",
        "spider_plot( pd.DataFrame({\n",
        "    'B-PER': bper,\n",
        "    'I-PER': iper,\n",
        "    'B-ORG': borg,\n",
        "    'I-ORG': iorg,\n",
        "    'B-LOC': bloc,\n",
        "    'I-LOC': iloc }),\n",
        "    ['deGasperi', 'Fiction', 'Wikinews'],\n",
        "    'Train set IOB tags',\n",
        "    1)\n",
        "\n",
        "spider_plot( pd.DataFrame({\n",
        "    'B-PER': bper_test,\n",
        "    'I-PER': iper_test,\n",
        "    'B-ORG': borg_test,\n",
        "    'I-ORG': iorg_test,\n",
        "    'B-LOC': bloc_test,\n",
        "    'I-LOC': iloc_test }),\n",
        "    ['deGasperi', 'Fiction', 'Wikinews'],\n",
        "    'Test set IOB tags',\n",
        "    2)\n",
        "\n",
        "spider_plot( pd.DataFrame({\n",
        "    'B-PER': per,\n",
        "    'B-ORG': org,\n",
        "    'B-LOC': loc}),\n",
        "    ['Moro', 'deGasperi', 'Fiction', 'Wikinews'],\n",
        "    'Train set non-IOB tags',\n",
        "    3)\n",
        "\n",
        "spider_plot( pd.DataFrame({\n",
        "    'B-PER': per_test,\n",
        "    'B-ORG': org_test,\n",
        "    'B-LOC': loc_test}),\n",
        "    ['Moro', 'deGasperi', 'Fiction', 'Wikinews'],\n",
        "    'Test set non-IOB tags',\n",
        "    4)\n",
        "\n",
        "#spider_plot( pd.DataFrame({\n",
        "#    'doc_len': doc_len,\n",
        "#    'voc_size': voc_size,\n",
        "#    'n_punct': n_punct,}),\n",
        "#    ['Moro', 'deGasperi', 'Fiction', 'Wikinews'],\n",
        "#    'Train set document statistics',\n",
        "#    5)\n",
        "#\n",
        "#spider_plot( pd.DataFrame({\n",
        "#    'doc_len': doc_len_test,\n",
        "#    'voc_size': voc_size_test,\n",
        "#    'n_punct': n_punct_test,}),\n",
        "#    ['Moro', 'deGasperi', 'Fiction', 'Wikinews'],\n",
        "#    'Test set document statistics',\n",
        "#    6)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def stacked_bar_plot(col_names, data, labels_name, title, subplot_idx):\n",
        "    plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "    # Names of group and bar width\n",
        "    barWidth = 1\n",
        "    bars = np.zeros(len(col_names))\n",
        "    n_col = np.arange(len(col_names))\n",
        "    plt.subplot(BAR_ROW_N, BAR_COL_N, subplot_idx)\n",
        "\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        plt.bar(n_col, data[i], bottom=bars, edgecolor='white', width=barWidth, label=labels_name[i])\n",
        "        bars = np.add(bars, data[i]).tolist()\n",
        "\n",
        "    bars = np.add(bper, iper).tolist()\n",
        "    \n",
        "    # Custom X axis\n",
        "    plt.xticks(n_col, col_names, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "\n",
        "    \n",
        "    # Show graphic\n",
        "stacked_bar_plot(['Moro', 'deGasperi', 'Fiction', 'Wikinews'],\n",
        "                 [punct, [o[i]-punct[i] for i in range(len(o))]],\n",
        "                 ['punct', 'O'],\n",
        "                 'Train sets',\n",
        "                 1)\n",
        "\n",
        "stacked_bar_plot(['Moro', 'deGasperi', 'Fiction', 'Wikinews'],\n",
        "                 [punct_test, [o_test[i]-punct_test[i] for i in range(len(o_test))]],\n",
        "                 ['punct', 'O'],\n",
        "                 'Test sets',\n",
        "                 2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyT4H448AUO6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#BIO_PATH = 'BIO_tag_NER_notation'\n",
        "#nonBIO_PATH = 'Inside_outside_NER_notation'\n",
        "\n",
        "#function to check if 2 tsv files are equal\n",
        "def check_equal(file1, file2):\n",
        "\tdf1 = pd.read_csv(file1, sep='\\t')\n",
        "\tdf2 = pd.read_csv(file2, sep='\\t')\n",
        "\t#printf the path of the two filr, length of the 2 files, and if they are equal\n",
        "\tprint(file1, \"\\n\", \n",
        "       \t  file2, \"\\n\",\n",
        "\t\t    \"equal: \", df1.equals(df2), \"\\n\\n\")\n",
        "\n",
        "\n",
        "#########################à BIO TAGGER ########################################\n",
        "\n",
        "oTag = \"O\"  \n",
        "types = set()\n",
        "\n",
        "files = {\n",
        "\t\"wikinews_train.tsv\"\t: BIO_PATH + \"automatic/WN_train.tsv\",\n",
        "\t\"wikinews_test.tsv\"\t\t: BIO_PATH + \"automatic/WN_dev.tsv\",\n",
        "\t\"fiction_train.tsv\"\t\t: BIO_PATH + \"automatic/FIC_train.tsv\",\n",
        "\t\"fiction_test.tsv\"\t\t: BIO_PATH + \"automatic/FIC_dev.tsv\",\n",
        "\t\"degasperi_train.tsv\"\t: BIO_PATH + \"automatic/ADG_train.tsv\",\n",
        "\t\"degasperi_test.tsv\"\t: BIO_PATH + \"automatic/ADG_dev.tsv\",\n",
        "\t\"moro_train.tsv\"\t\t: BIO_PATH + \"automatic/MR_train.tsv\",\n",
        "\t\"moro_test.tsv\"\t\t\t: BIO_PATH + \"automatic/MR_dev.tsv\",\n",
        "}\n",
        "\n",
        "count = {}\n",
        "\n",
        "for file in files:\n",
        "\twith open(os.path.join(nonBIO_PATH, file), \"r\") as f:\n",
        "\t\toutFile = files[file]\n",
        "\t\tcount[outFile] = {\"sentences\": 0, \"tags\": {}, \"tokens\": 0}\n",
        "\n",
        "\t\tsentences = []\n",
        "\t\tthisSentence = []\n",
        "\n",
        "\t\tfor line in f:\n",
        "\t\t\tline = line.strip()\n",
        "\t\t\tif len(line) == 0:\n",
        "\t\t\t\tif len(thisSentence) > 0:\n",
        "\t\t\t\t\tsentences.append(thisSentence)\n",
        "\t\t\t\t\tthisSentence = []\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tparts = line.split(\"\\t\")\n",
        "\t\t\tthisSentence.append(parts)\n",
        "\t\t\tcount[outFile][\"tokens\"] += 1\n",
        "\n",
        "\t\tif len(thisSentence) > 0:\n",
        "\t\t\tsentences.append(thisSentence)\n",
        "\n",
        "\t\tcount[outFile][\"sentences\"] = len(sentences)\n",
        "\n",
        "\t\tfor sentence in sentences:\n",
        "\t\t\tpreviousNer = oTag\n",
        "\t\t\tfor token in sentence:\n",
        "\t\t\t\tner = token[1]\n",
        "\t\t\t\tnewNer = ner\n",
        "\t\t\t\tif ner != oTag:\n",
        "\t\t\t\t\tif previousNer != ner:\n",
        "\t\t\t\t\t\tif ner not in count[outFile][\"tags\"]:\n",
        "\t\t\t\t\t\t\tcount[outFile][\"tags\"][ner] = 0\n",
        "\t\t\t\t\t\tnewNer = \"B-\" + ner\n",
        "\t\t\t\t\t\tcount[outFile][\"tags\"][ner] += 1\n",
        "\t\t\t\t\t\ttypes.add(ner)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tnewNer = \"I-\" + ner\n",
        "\t\t\t\ttoken[1] = newNer\n",
        "\t\t\t\tpreviousNer = ner\n",
        "\n",
        "\t\twith open(outFile, \"w\") as fw:\n",
        "\t\t\tfor sentence in sentences:\n",
        "\t\t\t\tfor token in sentence:\n",
        "\t\t\t\t\tfw.write(token[0])\n",
        "\t\t\t\t\tfw.write(\"\\t\")\n",
        "\t\t\t\t\tfw.write(token[1])\n",
        "\t\t\t\t\tfw.write(\"\\n\")\n",
        "\t\t\t\tfw.write(\"\\n\")\n",
        "\n",
        "#########################à CHECK ########################################\n",
        "comp = [\n",
        "\t[BIO_PATH + \"automatic/WN_train.tsv\", \t'./' + BIO_PATH + '/wikinews_train_BIO.tsv'],\n",
        "\t[BIO_PATH + \"automatic/WN_dev.tsv\", \t'./' + BIO_PATH + '/wikinews_test_BIO.tsv'],\n",
        "\t[BIO_PATH + \"automatic/FIC_train.tsv\", \t'./' + BIO_PATH + '/fiction_train_BIO.tsv'],\n",
        "\t[BIO_PATH + \"automatic/FIC_dev.tsv\", \t'./' + BIO_PATH + '/fiction_test_BIO.tsv'],\n",
        "\t[BIO_PATH + \"automatic/ADG_train.tsv\", \t'./' + BIO_PATH + '/degasperi_train_BIO.tsv'],\n",
        "\t[BIO_PATH + \"automatic/ADG_dev.tsv\", \t'./' + BIO_PATH + '/degasperi_test_BIO.tsv'],\n",
        "\t[BIO_PATH + \"automatic/MR_train.tsv\", \t'./' + BIO_PATH + '/moro_train_BIO.tsv'],\n",
        "\t[BIO_PATH + \"automatic/MR_dev.tsv\", \t'./' + BIO_PATH + '/moro_test_BIO.tsv'],\n",
        "]\n",
        "\n",
        "for i in comp:\n",
        "\tcheck_equal(i[0], i[1])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "jfZAu7CMRzP7",
        "WtEjHNHVAUOs",
        "0u32r8WVcKps",
        "AIj4qBulAUOt",
        "qdsB2Wg9393M",
        "6PMsuTVlfsNw",
        "tgn1LECxAUOy",
        "6Ls1yQMgQ_GL",
        "nnJ0Rfx5AUO2",
        "_iW_yMemOo1l",
        "WCuMssv9yT-v"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}